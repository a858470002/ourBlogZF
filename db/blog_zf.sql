-- phpMyAdmin SQL Dump
-- version 3.4.10.1deb1
-- http://www.phpmyadmin.net
--
-- Host: localhost
-- Generation Time: Mar 03, 2017 at 12:53 PM
-- Server version: 5.5.54
-- PHP Version: 5.3.10-1ubuntu3.26

SET SQL_MODE="NO_AUTO_VALUE_ON_ZERO";
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;

--
-- Database: `blog_zf`
--

-- --------------------------------------------------------

--
-- Table structure for table `article`
--

CREATE TABLE IF NOT EXISTS `article` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` varchar(64) NOT NULL,
  `formaltext` text NOT NULL,
  `column` int(32) NOT NULL,
  `user_id` int(11) NOT NULL,
  `link` varchar(2000) DEFAULT NULL,
  `is_link` int(11) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=40 ;

--
-- Dumping data for table `article`
--

INSERT INTO `article` (`id`, `title`, `formaltext`, `column`, `user_id`, `link`, `is_link`) VALUES
(1, '测试文章', '测试符号：\r\n！@#￥%……&×（）——+\r\n1234567890-=\r\n{}：”《》？\r\n【】；’，。/\r\n!@#$%^&*()_+\r\n{}:"<>?\r\n[];'',./', 5, 1, NULL, 0),
(2, '开发团队的效率', '我之前写过一篇叫《加班与效率》的文章，从概念上说了一些我对“效率”的认识，但是那篇文章趋于概念化，对于一些没有经历过这样的环境的同学来说，可能会觉得太抽象了。很早以前就想写一篇更具体一点的，可执行的文章与《加班与效率》这篇文章相辉映，并再把我两年前在杭州QCon上的那个“鼓吹工程师文化”的《建一支强大的小团队》（新浪微盘）的观点再加强一下。\r\n　　但是我遇到了一些思维方式上的麻烦——我讲的总是从我的经历背景出发，没有从其它人的经历背景来讲。这就好像，我在酷壳里说了很多东西（比如：专职的QA，Code Review很重要，编程年龄，创业的，Rework的……），有好些人觉得是不可能甚至太理想，其实我说的那些东西都是实实在在存在的，也是我所经历过的。于是，不同的经历，不同的环境，不同的眼界，造成了——有些人不理解我说的，而我也不能理解他们所说的。\r\n　　所以，过去的这段时间我一有机会就找一些人交流并观察一些身边的事情，并去试着跟从和理解那些我不能理解的东西。现在觉得差不多了，所以，写下了这篇文章。（但越是去理解对方，我就越坚持我的观点，所以这篇文章可能还是会出现鸡同鸭讲的情形，无所谓了）\r\n　　本文不讨论任何业务上的效率问题，只讨论软件开发或是软件工程中的效率问题。虽然产品和业务上的效率问题是根本，但是因为本文不是拉仇恨的，我也不想混在一起谈，所以请原谅我在这里先说开发团队的，以后重新开篇文章专门谈产品和业务的。\r\n　　我下面会罗列几个非常典型的开发方式——软件开发中的“锁”，接力棒式软件开发，保姆式软件开发，WatchDog软件开发，故障驱动式软件开发。\r\n　　软件开发中的“锁”\r\n　　如果你搞过并发编程，你一定知道什么是“锁”，锁就是用来同步和互斥。我发现有好些开发部门里的各个开发团队间存在很多锁。比如：\r\n技术能力上的锁。有一个项目需要在不同的地方做开发，这些模块用到不同的技术，比如：Java, C/C++, Python，Javascript，但是，这个团队里的每一个开发人员就只懂一门语言，于是，需要配合，需要任务排期，同步互斥锁就很多，于是，一个本来只需要2个人干3周的的工作变成了8个人干两个月。\r\n负责模块上的锁。同理，不同的人负责不同的模块，于是一个项目要动好多模块，那么你就需要把这些模块的人找过来，和上面一样。每个人都有自己的时间安排，人越多，锁越多。于是，一个来来只需要2个人干2两周的事，变成了7、8个人干一个多月。\r\n　　我上面并非瞎扯，这都是事实。我们可以看到，\r\n时间锁、进度锁。这堆有不同技能或是负责不同模块的开发人员有锁，有锁你就要等，他们有自己的安排，所以，要协作起来，你就需要排期，去同步。而参与的人越多，你的锁就越多。你协调他们的时间就更复杂。\r\n沟通锁、利益锁。而且，最恐怖的事情是，他们之间的沟通成本巨大。他们会花大量的时间在讨论，一个功能是实现在你那边，还是我这边，每个人都有自己的利益和算盘。无形中增加了很多推诿、官僚和政治上的东西。\r\n　　有时候，我们会觉得分工和分模块是产生效率的前提，但是实际情况并不是这样。我们也可以看到，所谓的“分工”被彻彻底底的滥用了。他们把“分工”当成了永远只干一件事的借口。\r\n　　【解决方案】\r\n　　一个程序员应该能够掌握多个语言，也能够负责多个模块甚至不同的职责。如果一个程序员觉得多学习一门语言，多掌握一个模块是件很困难的事，那么这个程序员本质上是不合格的。\r\n　　“接力棒式”软件开发\r\n　　在有各种“工作锁”的软件开发团队里，一般都无法避免“接力棒式”的开发。也就是说，底层的C程序员干完了，交给上层的Java程序员，然后再交给更上层的前端程序员，最后再交给运维人员。这就是接力棒式的开发。\r\n　　而且，更糟糕的是，如果在引入了软件流程下，这种“接力棒的方式”真是会把你搞崩溃的。比如下游团队开发一个月，交给QA测试一个月，再交给运维分步上线一个月，然后，上游团队拿到下游开发的API后开发一个月，再交给自己的QA测试一个月，然后再交给自己的运维上线一个月，于是，半年就这样过去了。这是一个由一个一个小瀑布叠出来的一个大瀑布。\r\n　　哦，你会说，这个好办啊，上下游不会先商定好接口么？然后做并行开发么？是的，这是其中的一个优化方式，但是需要很好的接口设计。但是，在实际过程中，你会发现（这时我并非信口开河，我说的都是事实），\r\n如果这两个上下游团队在一起还好办，要是不在一起，那么，实际情况是，后面的团队会等到前面的团队提测了，才开始开发，本质上就是串行开发的。\r\n如果有更多的团队呢？比如：A团队 -> B团队 -> C团队 ->D团队呢。接口就变得非常地关键了。而在实际情况下，因为没有好的接口设计人员，所以，在开发过程经常性地修改接口，或者是因为接口不好用也只得忍着。\r\n　　【解决方案】\r\n　　我以前写过一篇叫《IoC/DIP其实是一种管理思想》，对于这种接力棒的方式，应该反过来，如果业务应用团队是A团队，那B/C/D团队应该把自己的做成一个开发框架也好，服务化也好，让应用团队自己来接入。比如：前端做好一个前端开发框架，PE做好一个运维开发框架、各种工具，共享模块团队做好开发框架，让应用团队自己来接入，而不是帮他做。你会发现，在这么多团队各自P2P勾兑出来的很随意的接口的所带来的成本已经远超过一个统一标准的协议。\r\n　　“保姆式”软件开发\r\n　　所谓“保姆式”软件开发就是——我只管吃饭，不管做菜洗碗，就像——衣来伸手，饭来张口的“小皇帝”一样，身边有一堆太监或宫女，不然生活不能自理。这种情况经常见于开发和测试，开发和运维间的关系。很多公司，测试和运维都成了开发的保姆。\r\n　　我就能看到，很多开发快速写完代码后基本上都不怎么测试就交给QA去测试了，QA一测，我草，各种问题，而只会做黑盒的QA并不能马上就能确定是代码的问题还是环境的问题，所以还要花大量时间排除不是环境问题，才给开发报BUG。很多问题，可能只需要做个Code Review，做个单测就可以发现了，硬要交给QA。运维也是一样的，开发出来的软件根本就没有考虑什么运维的东西，因为有运维人员，所以我才不考虑呢。\r\n　　这和我们带孩子的道理是一样的，对于孩子来说，如果父母帮孩子做得越多，孩子就越觉得理所应当，就越不会去做。\r\n　　“保姆式”开发一般会进化成“保安式”开发。\r\n因为你的团队开发人员的能力不行，设计不行，Code Reivew/UT不做，你就只能找堆QA看着他。\r\n因为Dev/QA只管功能不管运维，所以，还得找堆运维人员看着他们。\r\n因为你的技术人员不懂业务，不懂需求，需要再找个BA，找个产品经理来指挥他。\r\n因为你的技术人员不会管理项目，所以，再搞个项目经理，找个敏捷教练、以及SQA来管着他。\r\n　　就这样，你不行，我找人来看着你，看你的人不行，我再找人来看着看你的人……层层保姆，层层保安。于是，你就会发现，团队或部门里的人员越来越多，你整天都在开会，整天都在互相解释，互相争吵，会扯淡的人越来越多。那还有个屁的效率。', 1, 1, NULL, 0),
(3, '从Code Review谈如何做技术', '这两天，在微博上表达了一下Code Review的重要性。因为翻看了阿里内部的Review Board上的记录，从上面发现Code Review做得好的是一些比较偏技术的团队，而偏业务的技术团队基本上没有看到Code Review的记录。当然，这并不能说没有记录他们就没有做Code Review，于是，我就问了一下以前在业务团队做过的同事有没有Code Review，他告诉我不但没有Code Review，而且他认为Code Review没用，因为：\r\n　　1）工期压得太紧，时间连coding都不够，以上线为目的。\r\n　　2）需求老变，代码的生命周期太短。所以，写好的代码没有任何意义，烂就烂吧，反正与绩效无关。\r\n　　我心里非常不认同这样的观点，我觉得我是程序员，我是工程师，就像医生一样，不是把病人医好就好了，还要对病人的长期健康负责。对于常见病，要很快地医好病人很简单，下猛药，大量使用抗生素，好得飞快。但大家都知道，这明显是“饮鸩止渴”、“竭泽而渔”的做法。医生需要有责任心和医德，我也觉得程序员工程师也要有相应的责任心和相应的修养。东西交给我我必需要负责，我觉得这种负责和修养不是”做出来“就了事了，而是要到“做漂亮”这个级别，这就是“山寨”和“工业”的差别。而只以“做出来”为目的标准，我只能以为，这样的做法只不过是“按部就班”的堆砌代码罢了，和劳动密集型的“装配生产线”和“砌砖头”没有什么差别，在这种环境里呆着还不如离开。\r\n　　老实说，因为去年我在业务团队的时候，我的团队也没有做Code Review，原因是多样的。其中一个重要原因是，我刚来阿里，所以，需要做的是在适应阿里的文化，任何公司都有自己的风格和特点，任何公司的做法都有他的理由和成因，对于我这样的一个初来者，首要的是要适应和观察，不要对团队做太多的改动，跟从、理解和信任是融入的关键。（注：在建北京团队和不要专职的测试人员上我都受到了一些阻力），所以跟着团队走没有玩Code Review。干了一年后，觉得我妥协了很多我以前所坚持的东西，觉得自己的标准在降低，想一想后背拔凉拔凉的，所以我决定坚持，而且还要坚持高标准。\r\n　　对于Code Review很重要的这个观点，在微博上抛出来后，被一些阿里的工程师，架构师/专家，甚至资深架构师批评，我在和他们回复和讨论的过程中，居然发现有个“因为对方用户的设置”我无法回复了（我被拉黑了，还有一些直接就是冷讽和骂人了，微博中我就直接删除了）。这些批评我的阿里工程师/架构师的观点总结一下如下：（顺便说一下，阿里内还是有很多团队坚持做Code Review的）\r\n　　1）到业务团队体会一下，倒逼工期的项目有多少？订好交付日期后再要求提前1个月的有多少？现在是做到已经不容易，更不谈做得漂亮！。\r\n　　2）Code Review是一种教条，意义不大，有测试，只要不出错，就可以了。\r\n　　3）目标都是改进质量，有限的投入总希望能有最大的产出，不同沉湎改进质量的方式不一样，业务应用开发忙的跟狗一样，而且业务逻辑变化快，通用性差，Code Review的成本要比底层高。\r\n　　4）现在的主要矛盾是倒排出来的工期和不靠谱的程序员之间的矛盾，我认为Code Review不是解决这个问题的银弹。不从实际情况出发光打正义的嘴炮实在太过于自慰了 。\r\n　　我们可以看到，上面观点其实和Code Review没有太多关系，其实是在抱怨另外的问题。这些观点其实是技术团队和业务团队的矛盾，但不知道为什么强加给了我的“Code Review很重要”的这个观点，然后这些观点反过来冲击“Code Reivew”，并说“Code Review无用”。这种讨论问题的方式在很常见，你说A，我说B，本来A、B是两件事，但就是要混为一谈，然后似是而非的用B来证明你的A观点是错的。（也许，这些工程师/架构师心存怨气，需要一个发泄的通道）\r\n　　我觉得，很多时候，人思考问题思考不清楚，很大一部分原因是因为把很多问题混为一谈，连我自己有些时候都会这样。引以为戒。\r\n　　即然被混为一谈，那我就来拆分一下，也是下面这三个问题：\r\nCode Review有没有用的问题。\r\nCode Review做不起来的问题。\r\n业务变化快，速度快的问题，技术疲于跟命。\r\n　　Code Review\r\n　　你Google一下Code Reivew这个关键词，你就会发现Code Review的好处基本上是不存在争议的，有很多很多的文章和博文都在说Code Review的重要性，怎么做会更好，而且很多公司在面试过程中会加入“Code Review”的问题。打开Wikipedia的词条你会看到这样的描述——\r\n卡珀斯·琼斯（Capers Jones）分析了超过12,000个软件开发项目，其中使用正式代码审查的项目，发现潜在缺陷率约在60-65%之间，若是非正式的代码审查，发现潜在缺陷率不到50%。大部份的测试，发现的潜在缺陷率会在30%左右。\r\n对于一些关键的软件（例如安全关键系统的嵌入式软件），一般的代码审查速度约是一小时150行程序码，一小时审查数百行程序码的审查速度太快，可能无法找到程序中的问题。代码审查一般可以找到及移除约65%的错误，最高可以到85%。\r\n也有研究针对代码审查找到的缺陷类型进行分析。代码审查找到的缺陷中，有75%是和计算机安全隐患有关。对于产品生命周期很长的软件公司而言，代码审查是很有效的工具。\r\n　　Code Review的好处我觉得不用多说了，主要是让你的代码可以更好的组织起来，更易读，有更高的维护性，同时可以达到知识共享，找到bug只是其中的副产品。这个东西已经不新鲜了，你上网可以找到很多文章，我就不多说了。就像你写程序要判断错误一样，Code Review也是最基本的常识性的东西。\r\n　　我从2002年开始就浸泡在严格的Code Review中，我的个人成长和Code Review有很大的关系，如果我的成长过程中没有经历过Code Review这个事，我完全不敢想像。\r\n　　我个人认为代码有这几种级别：1）可编译，2）可运行，3）可测试，4）可读，5）可维护，6）可重用。通过自动化测试的代码只能达到第3）级，而通过Code Review的代码少会在第4）级甚至更高。关于Code Review，你可以参看本站的《Code Review中的几个提示》\r\n　　可见，Code Review直接关系到了你的工程能力！\r\n　　Code Review 的问题\r\n　　有下面几个情况会让你的Code Review没有效果。\r\n　　首当其冲的是——“人员能力不足”，我经历过这样的情况，Code Review的过程中，大家大眼瞪小眼，没有什么好的想法，不知道什么是好的代码，什么是不好的代码。导致Code Review大多数都在代码风格上。今天，我告诉你，代码风格这种事，是每个程序员自查的事情，不应该浪费大家的时间。对此，我有两个建议：1）你团队的人招错了，该换血了。2）让你团队的人花时候阅读一下《代码大全》这本书（当然，还要读很多基础知识的书）。\r\n　　次当其冲的是——“结果更重要”，也就是说，做出来更重要，做漂亮不重要。因为我的KPI和年终奖based on how many works I’ve done！而不是How perfect they are ! 这让我想到那些天天在用Spring MVC做CRUD网页的工程师，我承认，他们很熟练。大量的重复劳动。其实，仔细想一下好多东西是可以框架化，模板化，或是自动生成的。所以，为了堆出这么多网页就不停地去堆，做的东西是很多，但是没有任何成长。急功近利，也许，你做得多，拿到了不错的年终奖，但是你失去的也多，失去了成为一个卓越工程师的机会。你本来可以让你的月薪在1-2年后翻1-2倍的，但一年后你只拿到了为数不多的年终奖。\r\n　　然后是——“人员的态度问题”，一方面就是懒，不想精益求精，只要干完活交差了事。对此，你更要大力开展Code Review了，让这种人写出来的代码曝光在更多人面前，让他为质量不好的代码蒙羞。另一方面，有人会觉得那是别人的模块，我不懂，也没时间去懂，不懂他的业务怎么做Code Review? 我只想说，如果你的团队里这样的“各个自扫门前雪”的事越多，那么这个团队也就越没主动性，没有主动性也就越不可能是个好团队，做的东西也不可能好。而对于个人来说，也就越不可能有成长。\r\n　　接下来是——“需求变化的问题”，有人认识，需求变得快，代码的生存周期比较短，不需要好的代码，反正过两天这些代码就会被废弃了。如果是一次性的东西，的确质量不需要太高，反正用了就扔。但是，我觉得多多少少要Review一下这个一次性的烂代码不会影响那些长期在用的代码吧，如果你的项目全部都是临时代码，那么你团队是不是也是一个临时团队？关于如果应对需求变化，你可以看看本站的《需求变化与IoC》《Unix的设计思想来应对多变的需求》的文章 ，从这些文章中，我相信你可以看到对于需求变化的代码质量需要的更高。\r\n　　最后是——“时间不够问题”，如果是业务逼得紧，让你疲于奔命，那么这不是Code Review好不好问题，这是需求管理和项目管理的问题以及别的非技术的问题。下面我会说。\r\n　　不管怎么样，上述Code Review的问题不应该成为“Code Review无意义”的理由或借口，这就好像“因噎废食”一样。干什么事都会有困难和问题的，有的人就这样退缩了，但有的人看得到利大于弊，还是去坚持，人与人的不同正在这个地方。这就是为什么运动会受伤，但还是会人去运动，而有人因为怕受伤就退缩了一样。\r\n　　被业务逼得太紧\r\n　　被业务逼得太紧，需求乱变，这其实和Code Review没有多大关系了。对此，我想先讲一个我的故事。\r\n　　我去年在阿里的聚石塔，刚去的时候，聚石塔正在做一个很大的重构——对架构的大调整。因此压了很多业务需求，等这个项目花了2-3个月做完了后，一下子涌入了30-50个需求，还规定一个月完成，搞得团队疲于奔命。在累了两周后，我仔细分析了一下这些需求，发现很多需求是在重复做阿里云已经做过的东西，还有一些需求是因为聚石塔这个平台不规范没有标准所产生的问题。于是，我做了这么三件事：\r\n　　1）重新定义聚石塔这个产品主要目标和范围，确定哪些该做，哪些不该做。\r\n　　2）为聚石塔制定标准 ，让阿里云的API都长得基本一样，并制订云资源的接入标准。\r\n　　3）推动重构阿里云的Portal系统，不再实现阿里云已经做过的东西，与阿里云紧密结合。\r\n　　这些事情推动起来并不容易，聚石塔的业务方一开始也不理解，我和产品一起做业务方的工作，而阿里云也被我逼得很惨（在这里一并感谢，尤其阿里云的同学，老实说，和阿里云跨团队合作中是我这么多年来感觉最好的一次，相当赞）。通过这个事，聚石塔需求一下就有质的下降了。搞得还有几个工程师来和我说，你这么搞，聚石塔就没事可干了。姑且不说工程师对聚石塔的理解是怎么样的。 我只想说，我大量地减少了需求，尽最大可能联合了该联合的人，而不是自己闭门造车，并让产品的目标和方向更明确了。做了这些事情后，大家不但不用加班，而且还有时间充电去学技术，并为聚石塔思考未来的方向和发展。去年公司996的时候，我的团队还在965（搞得跟异教徒似的），而且还有很多时间去专研新的东西。\r\n　　说这个故事，我不是为了得瑟，而是因为有些人在微博上抨击我是一个道貌岸然的只会谈概念讲道理的装逼犯。所以，我告诉大家我在聚石塔是怎么做的，我公开写在这里，你也可以向相关的同学去求证我说的是不是真的。也向你证明，我可能是个装逼犯，但绝不是只会谈概念讲道理的装逼犯。\r\n　　被业务方逼得紧不要抱怨，你没有时间被逼得像牲口一样工作，这个时候，你需要的是暂停一下想一想，为什么会像牲口一样？而这正是让你变得聪明的机会。\r\n　　我为你总结一下，\r\n　　1）你有没有去Review业务部门给你的这么多的需求，哪些是合理的，哪些是不合理的。在Amazon，开发工程师都会被教育拿到需求后一定要问——“为什么要做？业务影响度有多大？有多少用户受益？”，回答不清这个问题，没有数据的支持，就不做。所以，产品经理要做很多数据挖拙和用户调研的工作，而不是拍拍脑袋，听极少数的用户抱怨就要开需求了。\r\n　　2）产品经理也要管理和教育的。你要告诉你的产品经理：“你是一个好的产品经理，因为你不但对用户把握得很好，也会对软件工艺把握得很好。你不但会开出外在的功能性需求，也同样会开出内在的让软件系统更完善的非功能性需求。你不是在迁就用户，而是引导用户。你不会无限制地加功能，而是把握产品灵魂控制并简化功能。你会为自己要做的和不做东西的感到同样的自豪。”你要告诉你的产品经理：“做一个半成品不如做好半年产品”（更多这样的观点请参看《Rework摘录和感想》）\r\n　　3）做事情是要讲效率的。Amazon里喜欢使用一种叫T-Shirt Size Estimation的评估方法来优先做投入小产出大的“Happy Case”。关于什么是效率，什么是T-Shirt Size Estimation，你可以看看《加班与效率》一文 。\r\n　　4）需求总是会变化的，不要抱怨需求变化太快。你应该抱怨的是为什么我们没有把握好方向？老变？这个事就像踢足球一样，你要去的地方是球将要去的地方，而不是球现在的地方。你要知道球要去哪里，你就知道球之前是怎么动的，找到了运动轨迹后，你才知道球要去像何方。如果你都不知道球要去向何方，那你就是一只无头苍蝇一样，东一下西一下。\r\n　　当你忙得跟牲口一样，你应该停下来，问一下自己，自己成为牲口的原因，是不是就是因为自己做事时候像就牲口一样思考？\r\n　　其它\r\n　　最后，我在给阿里今年新入职的毕业生的“技塑人生”的分享中，我给他们布置了5、6个Homework，分享几个给大家：\r\n　　1）重构或写一个模块，把他做成真正的Elegant级别。\r\n　　2）与大家分享一篇或几篇技术文章 ，并收获10-30个赞。\r\n　　3）降低现有至少20%的重复工作或维护工作\r\n　　4）拒绝或简化一个需求（需要项目中所有的Stakeholders都同意）\r\n　　部署这些作业的原因，是我希望新入行的同学们对自己的工作坚持高的标准，我知道你们会因为骨感的现实而妥协，但是我希望你们就算在现实中妥协了也要在内心中坚持尽可能高的标准，不要习惯成自然，最后被社会这个大染缸给潜移默化了。因为你至少要对自己负责。对自己负责就是，用脚投票，如果妥协得受不了了就离开吧。\r\n　　芝兰生于空谷，不以无人而不芳！君子修身养道，不以穷困而改志！\r\n　　谢谢听我唠叨。', 1, 1, NULL, 0),
(4, 'C语言的整型溢出问题', '整型溢出有点老生常谈了，bla, bla, bla… 但似乎没有引起多少人的重视。整型溢出会有可能导致缓冲区溢出，缓冲区溢出会导致各种黑客攻击，比如最近OpenSSL的heartbleed事件，就是 一个buffer overread的事件。在这里写下这篇文章，希望大家都了解一下整型溢出，编译器的行为，以及如何防范，以写出更安全的代码。\r\n\r\n什么是整型溢出\r\nC语言的整型问题相信大家并不陌生了。对于整型溢出，分为无符号整型溢出和有符号整型溢出。\r\n\r\n对于unsigned整型溢出，C的规范是有定义的——“溢出后的数会以2^(8*sizeof(type))作模运算”，也就是说，如果一个unsigned char(1字符，8bits)溢出了，会把溢出的值与256求模。例如：\r\n\r\nunsigned char x = 0xff;\r\nprintf("%d\\n", ++x);\r\n上面的代码会输出：0 (因为0xff + 1是256，与2^8求模后就是0)\r\n\r\n对于signed整型的溢出，C的规范定义是“undefined behavior”，也就是说，编译器爱怎么实现就怎么实现。对于大多数编译器来说，算得啥就是啥。比如：\r\n\r\nsigned char x =0x7f; //注：0xff就是-1了，因为最高位是1也就是负数了\r\nprintf("%d\\n", ++x);\r\n上面的代码会输出：-128，因为0x7f + 0×01得到0×80，也就是二进制的1000 0000，符号位为1，负数，后面为全0，就是负的最小数，即-128。\r\n\r\n另外，千万别以为signed整型溢出就是负数，这个是不定的。比如：\r\n\r\nsigned char x = 0x7f;\r\nsigned char y = 0x05;\r\nsigned char r = x * y;\r\nprintf("%d\\n", r);\r\n上面的代码会输出：123\r\n\r\n相信对于这些大家不会陌生了。\r\n\r\n整型溢出的危害\r\n下面说一下，整型溢出的危害。\r\n\r\n示例一：整形溢出导致死循环\r\n\r\n... ...\r\n... ...\r\nshort len = 0;\r\n... ...\r\nwhile(len< MAX_LEN) {\r\n    len += readFromInput(fd, buf);\r\n    buf += len;\r\n}\r\n上面这段代码可能是很多程序员都喜欢写的代码(我在很多代码里看到过多次)，其中的MAX_LEN 可能会是个比较大的整型，比如32767，我们知道short是16bits，取值范围是-32768 到 32767 之间。但是，上面的while循环代码有可能会造成整型溢出，而len又是个有符号的整型，所以可能会成负数，导致不断地死循环。\r\n\r\n示例二：整形转型时的溢出\r\n\r\nint copy_something(char *buf, int len)\r\n{\r\n  #define MAX_LEN 256\r\n  char mybuf[MAX_LEN];</pre>\r\n<pre>  ... ...\r\n   ... ...\r\n   if(len > MAX_LEN){ // <---- [1]\r\n     return -1;\r\n   }\r\n   return memcpy(mybuf, buf, len);\r\n}\r\n上面这个例子中，还是[1]处的if语句，看上去没有会问题，但是len是个signed int，而memcpy则需一个size_t的len，也就是一个unsigned 类型。于是，len会被提升为unsigned，此时，如果我们给len传一个负数，会通过了if的检查，但在memcpy里会被提升为一个正数，于是我 们的mybuf就是overflow了。这个会导致mybuf缓冲区后面的数据被重写。\r\n\r\n示例三：分配内存\r\n\r\n关于整数溢出导致堆溢出的很典型的例子是，OpenSSH Challenge-Response SKEY/BSD_AUTH 远程缓冲区溢出漏洞。下面这段有问题的代码摘自OpenSSH的代码中的auth2-chall.c中的 input_userauth_info_response() 函数:\r\n\r\nnresp = packet_get_int();\r\nif (nresp > 0) {\r\n    response = xmalloc(nresp*sizeof(char*));\r\n    for (i = 0; i < nresp; i++)\r\n        response[i] = packet_get_string(NULL);\r\n}\r\n上面这个代码中，nresp是size_t类型(size_t一般就是unsigned int/long int)，这个示例是一个解数据包的示例，一般来说，数据包中都会有一个len，然后后面是data。如果我们精心准备一个len，比 如：1073741825(在32位系统上，指针占4个字节，unsigned int的最大值是0xffffffff，我们只要提供0xffffffff/4 的值——0×40000000，这里我们设置了0×4000000 + 1)， nresp就会读到这个值，然后nresp*sizeof(char*)就成了 1073741825 * 4，于是溢出，结果成为了 0×100000004，然后求模，得到4。于是，malloc(4)，于是后面的for循环1073741825 次，就可以干环事了(经过0×40000001的循环,用户的数据早已覆盖了xmalloc原先分配的4字节的空间以及后面的数据，包括程序代码，函数指 针，于是就可以改写程序逻辑。关于更多的东西，你可以看一下这篇文章《 Survey of Protections from Buffer-Overflow Attacks 》)。\r\n\r\n示例四：缓冲区溢出导致安全问题\r\n\r\nint func(char *buf1, unsigned int len1,\r\n         char *buf2, unsigned int len2 )\r\n{\r\n   char mybuf[256]; \r\n \r\n   if((len1 + len2) > 256){    //<--- [1]\r\n       return -1;\r\n   } \r\n \r\n   memcpy(mybuf, buf1, len1);\r\n   memcpy(mybuf + len1, buf2, len2); \r\n \r\n   do_some_stuff(mybuf); \r\n \r\n   return 0;\r\n}\r\n上面这个例子本来是想把buf1和buf2的内容copy到mybuf里，其中怕len1 + len2超过256 还做了判断，但是，如果len1+len2溢出了，根据unsigned的特性，其会与2^32求模，所以，基本上来说，上面代码中的[1]处有可能为假 的。(注：通常来说，在这种情况下，如果你开启-O代码优化选项，那个if语句块就全部被和谐掉了——被编译器给删除了)比如，你可以测试一下 len1=0×104， len2 = 0xfffffffc 的情况。\r\n\r\n这样的例子有很多很多，这些整型溢出的问题如果在关键的地方，尤其是在搭配有用户输入的地方，如果被黑客利用了，就会导致很严重的安全问题。\r\n\r\n关于编译器的行为\r\n在谈一下如何正确的检查整型溢出之前，我们还要来学习一下编译器的一些东西。请别怪我罗嗦。\r\n\r\n编译器优化\r\n\r\n如何检查整型溢出或是整型变量是否合法有时候是一件很麻烦的事情，就像上面的第四个例子一样，编译的优化参数-O/-O2/-O3基本上会假设你的程序不会有整形溢出。会把你的代码中检查溢出的代码给优化掉。\r\n\r\n关于编译器的优化，在这里再举个例子，假设我们有下面的代码(又是一个相当相当常见的代码)：\r\n\r\nint len;\r\nchar* data;\r\n \r\nif (data + len < data){\r\n    printf("invalid len\\n");\r\n    exit(-1);\r\n}\r\n上面这段代码中，len 和 data 配套使用，我们害怕len的值是非法的，或是len溢出了，于是我们写下了if语句来检查。这段代码在-O的参数下正常。但是在-O2的编译选项下，整个if语句块被优化掉了。\r\n\r\n你可以写个小程序，在gcc下编译(我的版本是4.4.7，记得加上-O2和-g参数)，然后用gdb调试时，用disass /m命信输出汇编，你会看到下面的结果(你可以看到整个if语句块没有任何的汇编代码——直接被编译器和谐掉了)：\r\n\r\n7           int len = 10;\r\n8              char* data = (char *)malloc(len);\r\n  0x00000000004004d4 <+4>:     mov    $0xa,%edi\r\n  0x00000000004004d9 <+9>:      callq  0x4003b8 <malloc@plt>\r\n9\r\n10            if (data + len < data){\r\n11                printf("invalid len\\n");\r\n12                 exit(-1);\r\n13            }\r\n14\r\n15      }\r\n  0x00000000004004de <+14>:     add     $0x8,%rsp\r\n  0x00000000004004e2 <+18>:    retq\r\n对此，你需要把上面 char* 转型成 uintptr_t 或是 size_t，说白了也就是把char*转成unsigned的数据结构，if语句块就无法被优化了。如下所示：\r\n\r\n[xml] view plain copy\r\nif ((uintptr_t)data + len <span class="tag">< (<span class="attribute">uintptr_t)<span class="attribute">data){  \r\n    <span class="attribute">... <span class="attribute">...  \r\n}</span></span></span></span></span>  \r\n关于这个事，你可以看一下C99的规范说明《 ISO/IEC 9899:1999 C specification 》第 §6.5.6 页，第8点，我截个图如下：(这段话的意思是定义了指针+/-一个整型的行为，如果越界了，则行为是undefined)\r\n\r\n\r\n\r\n注意上面标红线的地方，说如果指针指在数组范围内没事，如果越界了就是undefined，也就是说这事交给编译器实现了，编译器想咋干咋干，那怕你想把其优化掉也可以。在这里要重点说一下， C语言中的一个大恶魔—— Undefined! 这里都是“野兽出没”的地方，你一定要小心小心再小心 。\r\n\r\n花絮：编译器的彩蛋\r\n\r\n上面说了所谓的undefined行为就全权交给编译器实现，gcc在1.17版本下对于undefined的行为还玩了个彩蛋( 参看Wikipedia )。\r\n\r\n下面gcc 1.17版本下的遭遇undefined行为时，gcc在unix发行版下玩的彩蛋的源代码。我们可以看到，它会去尝试去执行一些游戏 NetHack ， Rogue 或是Emacs的 Towers of Hanoi ，如果找不到，就输出一条NB的报错。\r\n\r\nexecl("/usr/games/hack", "#pragma", 0); // try to run the game NetHack\r\nexecl("/usr/games/rogue", "#pragma", 0); // try to run the game Rogue\r\n// try to run the Tower''s of Hanoi simulation in Emacs.\r\nexecl("/usr/new/emacs", "-f","hanoi","9","-kill",0);\r\nexecl("/usr/local/emacs","-f","hanoi","9","-kill",0); // same as above\r\nfatal("You are in a maze of twisty compiler features, all different");\r\n正确检测整型溢出\r\n在看过编译器的这些行为后，你应该会明白——“ 在整型溢出之前，一定要做检查，不然，就太晚了 ”。\r\n\r\n我们来看一段代码：\r\n\r\nvoid foo(int m, int n)\r\n{\r\n    size_t s = m + n;\r\n    .......\r\n}\r\n上面这段代码有两个风险： 1)有符号转无符号 ， 2)整型溢出 。这两个情况在前面的那些示例中你都应该看到了。所以，你千万不要把任何检查的代码写在 s = m + n 这条语名后面，不然就太晚了 。undefined行为就会出现了——用句纯正的英文表达就是——“Dragon is here”——你什么也控制不住了。(注意：有些初学者也许会以为size_t是无符号的，而根据优先级 m 和 n 会被提升到unsigned int。其实不是这样的，m 和 n 还是signed int，m + n 的结果也是signed int，然后再把这个结果转成unsigned int 赋值给s)\r\n\r\n比如，下面的代码是错的：\r\n\r\nvoid foo(int m, int n)\r\n{\r\n    size_t s = m + n;\r\n    if ( m>0 && n>0 && (SIZE_MAX - m < n) ){\r\n        //error handling...\r\n    }\r\n}\r\n上面的代码中，大家要注意 (SIZE_MAX - m < n) 这个判断，为什么不用m + n > SIZE_MAX呢？因为，如果 m + n 溢出后，就被截断了，所以表达式恒真，也就检测不出来了。另外，这个表达式中，m和n分别会被提升为unsigned。\r\n\r\n但是上面的代码是错的，因为：\r\n\r\n1)检查的太晚了，if之前编译器的undefined行为就已经出来了(你不知道什么会发生)。\r\n\r\n2)就像前面说的一样，(SIZE_MAX - m < n) 可能会被编译器优化掉。\r\n\r\n3)另外，SIZE_MAX是size_t的最大值，size_t在64位系统下是64位的，严谨点应该用INT_MAX或是UINT_MAX\r\n\r\n所以，正确的代码应该是下面这样：\r\n\r\nvoid foo(int m, int n)\r\n{\r\n  size_t s = 0;\r\n  if ( m>0 && n>0 && ( UINT_MAX - m < n ) ){\r\n    //error handling...\r\n    return;\r\n  }\r\n  s = (size_t)m + (size_t)n;\r\n}\r\n在《 苹果安全编码规范 》(PDF)中，第28页的代码中：\r\n\r\n\r\n\r\n如果n和m都是signed int，那么这段代码是错的。正确的应该像上面的那个例子一样，至少要在n*m时要把 n 和 m 给 cast 成 size_t。因为，n*m可能已经溢出了，已经undefined了，undefined的代码转成size_t已经没什么意义了。(如果m和n是 unsigned int，也会溢出)，上面的代码仅在m和n是size_t的时候才有效。\r\n\r\n不管怎么说，《 苹果安全编码规范 》绝对值得你去读一读。\r\n\r\n上溢出和下溢出的检查\r\n\r\n前面的代码只判断了正数的上溢出overflow，没有判断负数的下溢出underflow。让们来看看怎么判断：\r\n\r\n对于加法，还好。\r\n\r\n#include <limits.h>\r\nvoid f(signed int si_a, signed int si_b) {\r\n  signed int sum;\r\n  if (((si_b > 0) && (si_a > (INT_MAX - si_b))) ||\r\n    ((si_b < 0) && (si_a < (INT_MIN - si_b)))) {\r\n    /* Handle error */\r\n    return;\r\n  }\r\n  sum = si_a + si_b;\r\n}\r\n对于乘法，就会很复杂(下面的代码太夸张了)：\r\n\r\nvoid func(signed int si_a, signed int si_b)\r\n{\r\n  signed int result;\r\n  if (si_a > 0) {  /* si_a is positive */\r\n    if (si_b > 0) {  /* si_a and si_b are positive */\r\n      if (si_a > (INT_MAX / si_b)) {\r\n        /* Handle error */\r\n      }\r\n    } else { /* si_a positive, si_b nonpositive */\r\n      if (si_b < (INT_MIN / si_a)) {\r\n        /* Handle error */\r\n      }\r\n    } /* si_a positive, si_b nonpositive */\r\n  } else { /* si_a is nonpositive */\r\n    if (si_b > 0) { /* si_a is nonpositive, si_b is positive */\r\n      if (si_a < (INT_MIN / si_b)) {\r\n        /* Handle error */\r\n      }\r\n    } else { /* si_a and si_b are nonpositive */\r\n      if ( (si_a != 0) && (si_b < (INT_MAX / si_a))) {\r\n        /* Handle error */\r\n      }\r\n    } /* End if si_a and si_b are nonpositive */\r\n  } /* End if si_a is nonpositive */\r\n \r\n  result = si_a * si_b;\r\n}\r\n更多的防止在操作中整型溢出的安全代码可以参看《 INT32-C. Ensure that operations on signed integers do not result in overflow 》\r\n\r\n其它\r\n对于C++来说，你应该使用STL中的numeric_limits::max() 来检查溢出。\r\n\r\n另外，微软的SafeInt类是一个可以帮你远理上面这些很tricky的类，下载地址： http://safeint.codeplex.com/\r\n\r\n对于Java 来说，一种是用JDK 1.7中Math库下的safe打头的函数，如safeAdd()和safeMultiply()，另一种用更大尺寸的数据类型，最大可以到BigInteger。\r\n\r\n可见，写一个安全的代码并不容易，尤其对于C/C++来说。对于黑客来说，他们只需要搜一下开源软件中代码有memcpy/strcpy之类的地方，然后看一看其周边的代码，是否可以通过用户的输入来影响，如果有的话，你就惨了。\r\n\r\n本文来自：Linux教程网', 6, 1, NULL, 0);
INSERT INTO `article` (`id`, `title`, `formaltext`, `column`, `user_id`, `link`, `is_link`) VALUES
(5, '从LongAdder看更高效的无锁实现', '接触到AtomicLong的原因是在看guava的LoadingCache相关代码时，关于LoadingCache，其实思路也非常简单清晰：用模板模式解决了缓存不命中时获取数据的逻辑，这个思路我早前也正好在项目中使用到。\r\n言归正传，为什么说LongAdder引起了我的注意，原因有二：\r\n作者是Doug lea ，地位实在举足轻重。\r\n他说这个比AtomicLong高效。\r\n我们知道，AtomicLong已经是非常好的解决方案了，涉及并发的地方都是使用CAS操作，在硬件层次上去做 compare and set操作。效率非常高。\r\n因此，我决定研究下，为什么LongAdder比AtomicLong高效。\r\n首先，看LongAdder的继承树：\r\nla1\r\n继承自Striped64，这个类包装了一些很重要的内部类和操作。稍候会看到。\r\n正式开始前，强调下，我们知道，AtomicLong的实现方式是内部有个value 变量，当多线程并发自增，自减时，均通过CAS 指令从机器指令级别操作保证并发的原子性。\r\n再看看LongAdder的方法：\r\nla2\r\n怪不得可以和AtomicLong作比较，连API都这么像。我们随便挑一个API入手分析，这个API通了，其他API都大同小异，因此，我选择了add这个方法。事实上,其他API也都依赖这个方法。\r\nla3\r\nLongAdder中包含了一个Cell 数组，Cell是Striped64的一个内部类，顾名思义，Cell 代表了一个最小单元，这个单元有什么用，稍候会说道。先看定义：\r\nla4\r\nCell内部有一个非常重要的value变量，并且提供了一个CAS更新其值的方法。\r\n回到add方法：\r\nla3\r\n这里，我有个疑问，AtomicLong已经使用CAS指令，非常高效了（比起各种锁），LongAdder如果还是用CAS指令更新值，怎么可能比AtomicLong高效了？ 何况内部还这么多判断！！！\r\n这是我开始时最大的疑问，所以，我猜想，难道有比CAS指令更高效的方式出现了？ 带着这个疑问，继续。\r\n第一if 判断，第一次调用的时候cells数组肯定为null,因此，进入casBase方法：\r\nla5\r\n原子更新base没啥好说的，如果更新成功，本地调用开始返回，否则进入分支内部。\r\n什么时候会更新失败？ 没错，并发的时候，好戏开始了，AtomicLong的处理方式是死循环尝试更新，直到成功才返回，而LongAdder则是进入这个分支。\r\n分支内部，通过一个Threadlocal变量threadHashCode 获取一个HashCode对象，该HashCode对象依然是Striped64类的内部类，看定义：\r\nla6\r\n有个code变量，保存了一个非0的随机数随机值。\r\n回到add方法：\r\nla3\r\n拿到该线程相关的HashCode对象后，获取它的code变量，as[(n-1)&h] 这句话相当于对h取模，只不过比起取模，因为是 与 的运算所以效率更高。\r\n计算出一个在Cells 数组中当先线程的HashCode对应的 索引位置，并将该位置的Cell 对象拿出来用CAS更新它的value值。\r\n当然，如果as 为null 并且更新失败，才会进入retryUpdate方法。\r\n看到这里我想应该有很多人明白为什么LongAdder会比AtomicLong更高效了，没错，唯一会制约AtomicLong高效的原因是高并发，高并发意味着CAS的失败几率更高， 重试次数更多，越多线程重试，CAS失败几率又越高，变成恶性循环，AtomicLong效率降低。 那怎么解决？ LongAdder给了我们一个非常容易想到的解决方案：减少并发，将单一value的更新压力分担到多个value中去，降低单个value的 “热度”，分段更新！！！\r\n这样，线程数再多也会分担到多个value上去更新，只需要增加value就可以降低 value的 “热度”  AtomicLong中的 恶性循环不就解决了吗？ cells 就是这个 “段” cell中的value 就是存放更新值的， 这样，当我需要总数时，把cells 中的value都累加一下不就可以了么！！\r\n当然，聪明之处远远不仅仅这里，在看看add方法中的代码，casBase方法可不可以不要，直接分段更新,上来就计算 索引位置，然后更新value？\r\n答案是不好，不是不行，因为，casBase操作等价于AtomicLong中的CAS操作，要知道，LongAdder这样的处理方式是有坏处的，分段操作必然带来空间上的浪费，可以空间换时间，但是，能不换就不换，看空间时间都节约~！ 所以，casBase操作保证了在低并发时，不会立即进入分支做分段更新操作，因为低并发时，casBase操作基本都会成功，只有并发高到一定程度了，才会进入分支，所以，Doug Lea对该类的说明是： 低并发时LongAdder和AtomicLong性能差不多，高并发时LongAdder更高效！\r\nla7\r\n但是，Doung Lea 还是没这么简单，聪明之处还没有结束……\r\n如此，retryUpdate中做了什么事，也基本略知一二了，因为cell中的value都更新失败(说明该索引到这个cell的线程也很多，并发也很高时) 或者cells数组为空时才会调用retryUpdate,\r\n因此，retryUpdate里面应该会做两件事：\r\n扩容，将cells数组扩大，降低每个cell的并发量，同样，这也意味着cells数组的rehash动作。\r\n 给空的cells变量赋一个新的Cell数组。\r\n是不是这样呢？ 继续看代码：\r\n代码比较长，变成文本看看，为了方便大家看if else 分支，对应的  { } 我用相同的颜色标注出来。可以看到，这个时候Doug Lea才愿意使用死循环保证更新成功~！\r\nfinal void retryUpdate(long x, HashCode hc, boolean wasUncontended) {   \r\n      int h = hc.code;   \r\n      boolean collide = false;                // True if last slot nonempty   \r\n      for (;;) {   \r\n          Cell[] as; Cell a; int n; long v;   \r\n          if ((as = cells) != null && (n = as.length) > 0) {// 分支1   \r\n              if ((a = as[(n - 1) & h]) == null) {   \r\n                  if (busy == 0) {            // Try to attach new Cell   \r\n                      Cell r = new Cell(x);   // Optimistically create   \r\n                      if (busy == 0 && casBusy()) {   \r\n                          boolean created = false;   \r\n                          try {               // Recheck under lock   \r\n                              Cell[] rs; int m, j;   \r\n                              if ((rs = cells) != null &&   \r\n                                      (m = rs.length) > 0 &&   \r\n                                      rs[j = (m - 1) & h] == null) {   \r\n                                  rs[j] = r;   \r\n                                  created = true;   \r\n                              }   \r\n                          } finally {   \r\n                              busy = 0;   \r\n                          }   \r\n                          if (created)   \r\n                              break;   \r\n                          continue;           // Slot is now non-empty   \r\n                      }   \r\n                  }   \r\n                  collide = false;   \r\n              }   \r\n              else if (!wasUncontended)       // CAS already known to fail   \r\n                  wasUncontended = true;      // Continue after rehash   \r\n              else if (a.cas(v = a.value, fn(v, x)))   \r\n                  break;   \r\n              else if (n >= NCPU || cells != as)   \r\n                  collide = false;            // At max size or stale   \r\n              else if (!collide)   \r\n                  collide = true;   \r\n              else if (busy == 0 && casBusy()) {   \r\n                  try {   \r\n                      if (cells == as) {      // Expand table unless stale   \r\n                          Cell[] rs = new Cell[n << 1];   \r\n                          for (int i = 0; i < n; ++i)   \r\n                              rs[i] = as[i];   \r\n                          cells = rs;   \r\n                      }   \r\n                  } finally {   \r\n                      busy = 0;   \r\n                  }   \r\n                  collide = false;   \r\n                  continue;                   // Retry with expanded table   \r\n              }   \r\n              h ^= h << 13;                   // Rehash  h ^= h >>> 17;   \r\n              h ^= h << 5;   \r\n          }   \r\n          else if (busy == 0 && cells == as && casBusy()) {//分支2   \r\n              boolean init = false;   \r\n              try {                           // Initialize table   \r\n                  if (cells == as) {   \r\n                      Cell[] rs = new Cell[2];   \r\n                      rs[h & 1] = new Cell(x);   \r\n                      cells = rs;   \r\n                      init = true;   \r\n                  }   \r\n              } finally {   \r\n                  busy = 0;   \r\n              }   \r\n              if (init)   \r\n                  break;   \r\n          }   \r\n          else if (casBase(v = base, fn(v, x)))   \r\n              break;                          // Fall back on using base   \r\n      }   \r\n      hc.code = h;                            // Record index for next time   \r\n  } \r\n分支2中，为cells为空的情况，需要new 一个Cell数组。\r\n分支1分支中，略复杂一点点：\r\n注意，几个分支中都提到了busy这个方法，这个可以理解为一个CAS实现的锁，只有在需要更新cells数组的时候才会更新该值为1，如果更新失败，则说明当前有线程在更新cells数组，当前线程需要等待。重试。\r\n回到分支1中，这里首先判断当前cells数组中的索引位置的cell元素是否为空，如果为空，则添加一个cell到数组中。\r\n否则更新 标示冲突的标志位wasUncontended 为 true ，重试。\r\n否则，再次更新cell中的value,如果失败，重试。\r\n。。。。。。。一系列的判断后，如果还是失败，下下下策，reHash,直接将cells数组扩容一倍，并更新当前线程的hash值，保证下次更新能尽可能成功。\r\n可以看到，LongAdder确实用了很多心思减少并发量，并且，每一步都是在”没有更好的办法“的时候才会选择更大开销的操作，从而尽可能的用最最简单的办法去完成操作。追求简单，但是绝对不粗暴。\r\n———————陈皓注————————\r\n最后留给大家思考的两个问题：\r\n1）是不是AtomicLong可以被废了？\r\n2）如果cell被创建后，原来的casBase就不走了，会不会性能更差？\r\n———————liuinsect注————————\r\n昨天和左耳朵耗子简单讨论了下，发现左耳朵耗子,耗哥对读者思维的引导还是非常不错的，在第一次发现这个类后，对里面的实现又提出了更多的问题，引导大家思考，值得学习。\r\n我们 发现的问题有这么几个（包括以上的问题），自己简单总结下，欢迎大家讨论：\r\n1. jdk 1.7中是不是有这个类？\r\n我确认后，结果如下：    jdk-7u51 版本上还没有  但是jdk-8u20版本上已经有了。代码基本一样 ，增加了对double类型的支持和删除了一些冗余的代码。有兴趣的同学可以去下载下JDK 1.8看看\r\n2. base有没有参与汇总？\r\nbase在调用intValue等方法的时候是会汇总的：\r\nLA10\r\n3. 如果cell被创建后，原来的casBase就不走了，会不会性能更差？ base的顺序可不可以调换?\r\n  刚开始我想可不可以调换add方法中的判断顺序，比如，先做casBase的判断？ 仔细思考后认为还是 不调换可能更好，调换后每次都要CAS一下，在高并发时，失败几率非常高，并且是恶性循环，比起一次判断，后者的开销明显小很多，还没有副作用（上一个问题，base变量在sum时base是会被统计的，并不会丢掉base的值）。因此，不调换可能会更好。\r\n4. AtomicLong可不可以废掉？\r\n我的想法是可以废掉了，因为，虽然LongAdder在空间上占用略大，但是，它的性能已经足以说明一切了,无论是从节约空的角度还是执行效率上，AtomicLong基本没有优势了，具体看这个测试（感谢Lemon的回复）:http://blog.palominolabs.com/2014/02/10/java-8-performance-improvements-longadder-vs-atomiclong/\r\n（全文完）', 3, 1, NULL, 0),
(6, '面向GC的Java编程', 'Java程序员在编码过程中通常不需要考虑内存问题，JVM经过高度优化的GC机制大部分情况下都能够很好地处理堆(Heap)的清理问题。以至于许多Java程序员认为，我只需要关心何时创建对象，而回收对象，就交给GC来做吧！甚至有人说，如果在编程过程中频繁考虑内存问题，是一种退化，这些事情应该交给编译器，交给虚拟机来解决。\r\n\r\n这话其实也没有太大问题，的确，大部分场景下关心内存、GC的问题，显得有点“杞人忧天”了，高老爷说过：\r\n\r\n过早优化是万恶之源。\r\n\r\n但另一方面，什么才是“过早优化”？\r\n\r\n如果我们第一次就把事情做对了，何乐而不为呢？\r\n\r\n事实上JVM的内存模型( JMM )理应是Java程序员的基础知识，处理过几次JVM线上内存问题之后就会很明显感受到，很多系统问题，都是内存问题。\r\n\r\n对JVM内存结构感兴趣的同学可以看下 浅析Java虚拟机结构与机制 这篇文章，本文就不再赘述了，本文也并不关注具体的GC算法，相关的文章汗牛充栋，随时可查。\r\n\r\n另外，不要指望GC优化的这些技巧，可以对应用性能有成倍的提高，特别是对I/O密集型的应用，或是实际落在YoungGC上的优化，可能效果只是帮你减少那么一点YoungGC的频率。\r\n\r\n但我认为，优秀程序员的价值，不在于其所掌握的几招屠龙之术，而是在细节中见真著，就像前面说的，如果我们可以一次把事情做对，并且做好，在允许的范围内尽可能追求卓越，为什么不去做呢？\r\n\r\n一、GC分代的基本假设\r\n\r\n大部分GC算法，都将堆内存做分代(Generation)处理，但是为什么要分代呢，又为什么不叫内存分区、分段，而要用面向时间、年龄的“代”来表示不同的内存区域？\r\n\r\nGC分代的基本假设是：\r\n\r\n绝大部分对象的生命周期都非常短暂，存活时间短。\r\n\r\n而这些短命的对象，恰恰是GC算法需要首先关注的。所以在大部分的GC中，YoungGC（也称作MinorGC）占了绝大部分，对于负载不高的应用，可能跑了数个月都不会发生FullGC。\r\n\r\n基于这个前提，在编码过程中，我们应该尽可能地缩短对象的生命周期。在过去，分配对象是一个比较重的操作，所以有些程序员会尽可能地减少new对象的次数，尝试减小堆的分配开销，减少内存碎片。\r\n\r\n但是，短命对象的创建在JVM中比我们想象的性能更好，所以，不要吝啬new关键字，大胆地去new吧。\r\n\r\n当然前提是不做无谓的创建，对象创建的速率越高，那么GC也会越快被触发。\r\n\r\n结论：\r\n\r\n分配小对象的开销分享小，不要吝啬去创建。\r\n\r\nGC最喜欢这种小而短命的对象。\r\n\r\n让对象的生命周期尽可能短，例如在方法体内创建，使其能尽快地在YoungGC中被回收，不会晋升(promote)到年老代(Old Generation)。\r\n\r\n二、对象分配的优化\r\n\r\n基于大部分对象都是小而短命，并且不存在多线程的数据竞争。这些小对象的分配，会优先在线程私有的 TLAB 中分配，TLAB中创建的对象，不存在锁甚至是CAS的开销。\r\n\r\nTLAB占用的空间在Eden Generation。\r\n\r\n当对象比较大，TLAB的空间不足以放下，而JVM又认为当前线程占用的TLAB剩余空间还足够时，就会直接在Eden Generation上分配，此时是存在并发竞争的，所以会有CAS的开销，但也还好。\r\n\r\n当对象大到Eden Generation放不下时，JVM只能尝试去Old Generation分配，这种情况需要尽可能避免，因为一旦在Old Generation分配，这个对象就只能被Old Generation的GC或是FullGC回收了。\r\n\r\n三、不可变对象的好处\r\n\r\nGC算法在扫描存活对象时通常需要从ROOT节点开始，扫描所有存活对象的引用，构建出对象图。\r\n\r\n不可变对象对GC的优化，主要体现在Old Generation中。\r\n\r\n可以想象一下，如果存在Old Generation的对象引用了Young Generation的对象，那么在每次YoungGC的过程中，就必须考虑到这种情况。\r\n\r\nHotspot JVM为了提高YoungGC的性能，避免每次YoungGC都扫描Old Generation中的对象引用，采用了 卡表(Card Table) 的方式。\r\n\r\n简单来说，当Old Generation中的对象发生对Young Generation中的对象产生新的引用关系或释放引用时，都会在卡表中响应的标记上标记为脏(dirty)，而YoungGC时，只需要扫描这些dirty的项就可以了。\r\n\r\n可变对象对其它对象的引用关系可能会频繁变化，并且有可能在运行过程中持有越来越多的引用，特别是容器。这些都会导致对应的卡表项被频繁标记为dirty。\r\n\r\n而不可变对象的引用关系非常稳定，在扫描卡表时就不会扫到它们对应的项了。\r\n\r\n注意，这里的不可变对象，不是指仅仅自身引用不可变的final对象，而是真正的Immutable Objects。\r\n\r\n四、引用置为null的传说\r\n\r\n早期的很多Java资料中都会提到在方法体中将一个变量置为null能够优化GC的性能，类似下面的代码：\r\n\r\n1\r\n2\r\n3\r\nList<String> list = new ArrayList<String>();\r\n// some code\r\nlist = null; // help GC\r\n事实上这种做法对GC的帮助微乎其微，有时候反而会导致代码混乱。\r\n\r\n我记得几年前 @rednaxelafx 在HLL VM小组中详细论述过这个问题，原帖我没找到，结论基本就是：\r\n\r\n在一个非常大的方法体内，对一个较大的对象，将其引用置为null，某种程度上可以帮助GC。\r\n\r\n大部分情况下，这种行为都没有任何好处。\r\n\r\n所以，还是早点放弃这种“优化”方式吧。\r\n\r\nGC比我们想象的更聪明。\r\n\r\n五、手动档的GC\r\n\r\n在很多Java资料上都有下面两个奇技淫巧：\r\n\r\n通过Thread.yield()让出CPU资源给其它线程。\r\n\r\n通过System.gc()触发GC。\r\n\r\n事实上JVM从不保证这两件事，而System.gc()在JVM启动参数中如果允许显式GC，则会触发FullGC，对于响应敏感的应用来说，几乎等同于自杀。\r\n\r\nSo，让我们牢记两点：\r\n\r\nNever use Thread.yield()。\r\n\r\nNever use System.gc()。除非你真的需要回收Native Memory。\r\n\r\n第二点有个Native Memory的例外，如果你在以下场景：\r\n\r\n使用了NIO或者NIO框架（Mina/Netty）\r\n\r\n使用了DirectByteBuffer分配字节缓冲区\r\n\r\n使用了MappedByteBuffer做内存映射\r\n\r\n由于Native Memory只能通过FullGC（或是CMS GC）回收，所以除非你非常清楚这时真的有必要，否则不要轻易调用System.gc()，且行且珍惜。\r\n\r\n另外为了防止某些框架中的System.gc调用（例如NIO框架、Java RMI），建议在启动参数中加上-XX:+DisableExplicitGC来禁用显式GC。\r\n\r\n这个参数有个巨大的坑，如果你禁用了System.gc()，那么上面的3种场景下的内存就无法回收，可能造成OOM，如果你使用了CMS GC，那么可以用这个参数替代：-XX:+ExplicitGCInvokesConcurrent。\r\n\r\n关于System.gc()，可以参考 @bluedavy 的几篇文章：\r\n\r\nCMS GC会不会回收Direct ByteBuffer的内存\r\n\r\n说说在Java启动参数上我犯的错\r\n\r\njava.lang.OutOfMemoryError:Map failed\r\n\r\n六、指定容器初始化大小\r\n\r\nJava容器的一个特点就是可以动态扩展，所以通常我们都不会去考虑初始大小的设置，不够了反正会自动扩容呗。\r\n\r\n但是扩容不意味着没有代价，甚至是很高的代价。\r\n\r\n例如一些基于数组的数据结构，例如StringBuilder、StringBuffer、ArrayList、HashMap等等，在扩容的时候都需要做ArrayCopy，对于不断增长的结构来说，经过若干次扩容，会存在大量无用的老数组，而回收这些数组的压力，全都会加在GC身上。\r\n\r\n这些容器的构造函数中通常都有一个可以指定大小的参数，如果对于某些大小可以预估的容器，建议加上这个参数。\r\n\r\n可是因为容器的扩容并不是等到容器满了才扩容，而是有一定的比例，例如HashMap的扩容阈值和负载因子(loadFactor)相关。\r\n\r\nGoogle Guava框架对于容器的初始容量提供了非常便捷的工具方法，例如：\r\n\r\n1\r\n2\r\n3\r\n4\r\n5\r\n6\r\n7\r\nLists.newArrayListWithCapacity(initialArraySize);\r\n \r\nLists.newArrayListWithExpectedSize(estimatedSize);\r\n \r\nSets.newHashSetWithExpectedSize(expectedSize);\r\n \r\nMaps.newHashMapWithExpectedSize(expectedSize);\r\n这样我们只要传入预估的大小即可，容量的计算就交给Guava来做吧。\r\n\r\n反例：\r\n\r\n如果采用默认无参构造函数，创建一个ArrayList，不断增加元素直到OOM，那么在此过程中会导致：\r\n\r\n多次数组扩容，重新分配更大空间的数组\r\n多次数组拷贝\r\n内存碎片\r\n七、对象池\r\n\r\n为了减少对象分配开销，提高性能，可能有人会采取对象池的方式来缓存对象集合，作为复用的手段。\r\n\r\n但是对象池中的对象由于在运行期长期存活，大部分会晋升到Old Generation，因此无法通过YoungGC回收。\r\n\r\n并且通常……没有什么效果。\r\n\r\n对于对象本身：\r\n\r\n如果对象很小，那么分配的开销本来就小，对象池只会增加代码复杂度。\r\n\r\n如果对象比较大，那么晋升到Old Generation后，对GC的压力就更大了。\r\n\r\n从线程安全的角度考虑，通常池都是会被并发访问的，那么你就需要处理好同步的问题，这又是一个大坑，并且同步带来的开销，未必比你重新创建一个对象小。\r\n\r\n对于对象池，唯一合适的场景就是当池中的每个对象的创建开销很大时，缓存复用才有意义，例如每次new都会创建一个连接，或是依赖一次RPC。\r\n\r\n比如说：\r\n\r\n线程池\r\n数据库连接池\r\nTCP连接池\r\n即使你真的需要实现一个对象池，也请使用成熟的开源框架，例如Apache Commons Pool。\r\n\r\n另外，使用JDK的ThreadPoolExecutor作为线程池，不要重复造轮子，除非当你看过AQS的源码后认为你可以写得比Doug Lea更好。\r\n\r\n八、对象作用域\r\n\r\n尽可能缩小对象的作用域，即生命周期。\r\n\r\n如果可以在方法内声明的局部变量，就不要声明为实例变量。\r\n\r\n除非你的对象是单例的或不变的，否则尽可能少地声明static变量。\r\n\r\n九、各类引用\r\n\r\njava.lang.ref.Reference有几个子类，用于处理和GC相关的引用。JVM的引用类型简单来说有几种：\r\n\r\nStrong Reference，最常见的引用\r\nWeak Reference，当没有指向它的强引用时会被GC回收\r\nSoft Reference，只当临近OOM时才会被GC回收\r\nPhantom Reference，主要用于识别对象被GC的时机，通常用于做一些清理工作\r\n当你需要实现一个缓存时，可以考虑优先使用WeakHashMap，而不是HashMap，当然，更好的选择是使用框架，例如Guava Cache。\r\n\r\n最后，再次提醒，以上的这些未必可以对代码有多少性能上的提升，但是熟悉这些方法，是为了帮助我们写出更卓越的代码，和GC更好地合作。', 4, 1, NULL, 0),
(7, 'C语言结构体里的成员数组和指针(关于零数组)', '单看这文章的标题，你可能会觉得好像没什么意思。你先别下这个结论，相信这篇文章会对你理解C语言有帮助。这篇文章产生的背景是在微博上，看到@Laruence同学出了一个关于C语言的题，微博链接。微博截图如下。我觉得好多人对这段代码的理解还不够深入，所以写下了这篇文章。\r\n\r\n\r\n\r\n为了方便你把代码copy过去编译和调试，我把代码列在下面：\r\n[cpp] view plain copy print?在CODE上查看代码片派生到我的代码片\r\n#include <stdio.h>  \r\nstruct str{  \r\n    int len;  \r\n    char s[0];  \r\n};  \r\n  \r\nstruct foo {  \r\n    struct str *a;  \r\n};  \r\n  \r\nint main(int argc, char** argv) {  \r\n    struct foo f={0};  \r\n    if (f.a->s) {  \r\n        printf( f.a->s);  \r\n    }  \r\n    return 0;  \r\n}  \r\n\r\n你编译一下上面的代码，在VC++和GCC下都会在14行的printf处crash掉你的程序。@Laruence说这个是个经典的坑，我觉得这怎么会是经典的坑呢？上面这代码，你一定会问，为什么if语句判断的不是f.a？而是f.a里面的数组？我个人觉得这主要还是对C语言理解不深，如果这算坑的话，那么全都是坑。\r\n接下来，你调试一下，或是你把14行的printf语句改成：\r\nprintf("%x\\n",f.a->s);\r\n你会看到程序不crash了。程序输出：4。 这下你知道了，访问0×4的内存地址，不crash才怪。于是，你一定会有如下的问题：\r\n1）为什么不是 13行if语句出错？f.a被初始化为空了嘛，用空指针访问成员变量为什么不crash？\r\n2）为什么会访问到了0×4的地址？靠，4是怎么出来的？\r\n3）代码中的第4行，char s[0] 是个什么东西？零长度的数组？为什么要这样玩？\r\n让我们从基础开始一点一点地来解释C语言中这些诡异的问题。\r\n\r\n·结构体中的成员\r\n\r\n首先，我们需要知道——所谓变量，其实是内存地址的一个抽像名字罢了。在静态编译的程序中，所有的变量名都会在编译时被转成内存地址。机器是不知道我们取的名字的，只知道地址。\r\n所以有了——栈内存区，堆内存区，静态内存区，常量内存区，我们代码中的所有变量都会被编译器预先放到这些内存区中。\r\n有了上面这个基础，我们来看一下结构体中的成员的地址是什么？我们先简单化一下代码：\r\nstruct test{\r\n    int i;\r\n    char *p;\r\n};\r\n上面代码中，test结构中i和p指针，在C的编译器中保存的是相对地址——也就是说，他们的地址是相对于struct test的实例的。\r\n\r\n如果我们有这样的代码：\r\nstruct test t;\r\n我们用gdb跟进去，对于实例t，我们可以看到：\r\n# t实例中的p就是一个野指针\r\n(gdb) p t\r\n$1 = {i = 0, c = 0''\\000'', d = 0 ''\\000'', p = 0x4003e0 "1\\355I\\211\\..."}\r\n \r\n# 输出t的地址\r\n(gdb) p &t\r\n$2 = (struct test *)0x7fffffffe5f0\r\n \r\n#输出(t.i)的地址\r\n(gdb) p &(t.i)\r\n$3 = (char **)0x7fffffffe5f0\r\n \r\n#输出(t.p)的地址\r\n(gdb) p &(t.p)\r\n$4 = (char **)0x7fffffffe5f4\r\n我们可以看到，t.i的地址和t的地址是一样的，t.p的址址相对于t的地址多了个4。说白了，t.i 其实就是(&t +0×0), t.p 的其实就是 (&t +0×4)。0×0和0×4这个偏移地址就是成员i和p在编译时就被编译器给hard code了的地址。于是，你就知道，不管结构体的实例是什么——访问其成员其实就是加成员的偏移量。\r\n\r\n下面我们来做个实验：\r\n[cpp] view plain copy print?在CODE上查看代码片派生到我的代码片\r\nstruct test{  \r\n    int i;  \r\n    short c;  \r\n    char *p;  \r\n};  \r\n   \r\nint main(){  \r\n    struct test *pt=NULL;  \r\n    return 0;  \r\n}  \r\n\r\n编译后，我们用gdb调试一下，当初始化pt后，我们看看如下的调试：（我们可以看到就算是pt为NULL，访问其中的成员时，其实就是在访问相对于pt的内址）\r\n(gdb) p pt\r\n$1 = (struct test *)0x0\r\n(gdb) p pt->i\r\nCannot access memoryat address 0x0\r\n(gdb) p pt->c\r\nCannot access memoryat address 0x4\r\n(gdb) p pt->p\r\nCannot access memoryat address 0x8\r\n注意：上面的pt->p的偏移之所以是0×8而不是0×6，是因为内存对齐了（我在64位系统上）。\r\n\r\n好了，现在你知道为什么原题中会访问到了0×4的地址了吧，因为是相对地址。\r\n相对地址有很好多处，其可以玩出一些有意思的编程技巧，比如把C搞出面向对象式的感觉来。\r\n\r\n·指针和数组的差别\r\n\r\n有了上面的基础后，你把源代码中的structstr结构体中的chars[0];改成char*s;试试看，你会发现，在13行if条件的时候，程序因为Cannot accessmemory就直接挂掉了。为什么声明成char s[0]，程序会在14行挂掉，而声明成char *s，程序会在13行挂掉呢？那么char*s 和char s[0]有什么差别呢？\r\n在说明这个事之前，有必要看一下汇编代码，用GDB查看后发现：\r\n·                                对于char s[0]来说，汇编代码用了lea指令，lea 0×04(%rax), %rdx\r\n·                                对于char*s来说，汇编代码用了mov指令，mov 0×04(%rax), %rdx\r\nlea全称load effective address，是把地址放进去，而mov则是把地址里的内容放进去。所以，就crash了。\r\n从这里，我们可以看到，访问成员数组名其实得到的是数组的相对地址，而访问成员指针其实是相对地址里的内容（这和访问其它非指针或数组的变量是一样的）\r\n换句话说，对于数组char s[10]来说，数组名 s 和 &s 都是一样的（不信你可以自己写个程序试试）。在我们这个例子中，也就是说，都表示了偏移后的地址。这样，如果我们访问 指针的地址（或是成员变量的地址），那么也就不会让程序挂掉了。\r\n\r\n正如下面的代码，可以运行一点也不会crash掉（你汇编一下你会看到用的都是lea指令）：\r\n[cpp] view plain copy print?在CODE上查看代码片派生到我的代码片\r\nstruct test{  \r\n    int i;  \r\n    short c;  \r\n    char *p;  \r\n    char s[10];  \r\n};  \r\n   \r\nint main(){  \r\n    struct test *pt=NULL;  \r\n    printf("&s = %x\\n",pt->s); //等价于printf("%x\\n", &(pt->s) );  \r\n    printf("&i = %x\\n",&pt->i); //因为操作符优先级，我没有写成&(pt->i)  \r\n    printf("&c = %x\\n",&pt->c);  \r\n    printf("&p = %x\\n",&pt->p);  \r\n    return 0;  \r\n}  \r\n\r\n\r\n\r\n·关于零长度的数组\r\n\r\n首先，我们要知道，0长度的数组在ISO C和C++的规格说明书中是不允许的。这也就是为什么在VC++2012下编译你会得到一个警告：“arning C4200: 使用了非标准扩展 : 结构/联合中的零大小数组”。\r\n那么为什么gcc可以通过而连一个警告都没有？那是因为gcc为了预先支持C99的这种玩法，所以，让“零长度数组”这种玩法合法了。关于GCC对于这个事的文档在这里：“Arrays of Length Zero”，文档中给了一个例子（我改了一下，改成可以运行的了）：\r\n[cpp] view plain copy print?在CODE上查看代码片派生到我的代码片\r\n#include<stdlib.h>  \r\n#include<string.h>  \r\n   \r\nstruct line {  \r\n   int length;  \r\n   char contents[0]; // C99的玩法是：char contents[]; 没有指定数组长度  \r\n};  \r\n   \r\nint main(){  \r\n    int this_length=10;  \r\n    struct line *thisline = (struct line *)  \r\n                     malloc (sizeof (structline) + this_length);  \r\n    thisline->length = this_length;  \r\n    memset(thisline->contents, ''a'',this_length);  \r\n    return 0;  \r\n}  \r\n上面这段代码的意思是：我想分配一个不定长的数组，于是我有一个结构体，其中有两个成员，一个是length，代表数组的长度，一个是contents，代码数组的内容。后面代码里的 this_length（长度是10）代表是我想分配的数据的长度。（这看上去是不是像一个C++的类？）这种玩法英文叫：Flexible Array，中文翻译叫：柔性数组。\r\n我们来用gdb看一下：\r\n(gdb) p thisline\r\n$1 = (struct line *)0x601010\r\n \r\n(gdb) p *thisline\r\n$2 = {length = 10,contents = 0x601010 "\\n"}\r\n \r\n(gdb) pthisline->contents\r\n$3 = 0x601014"aaaaaaaaaa"\r\n我们可以看到：在输出*thisline时，我们发现其中的成员变量contents的地址居然和thisline是一样的（偏移量为0×0??!!）。但是当我们输出thisline->contents的时候，你又发现contents的地址是被offset了0×4了的，内容也变成了10个‘a’。（我觉得这是一个GDB的bug，VC++就能很好的显示）\r\n我们继续，如果你sizeof(char[0])或是 sizeof(int[0]) 之类的零长度数组，你会发现sizeof返回了0，这就是说，零长度的数组是存在于结构体内的，但是不占结构体的size。你可以简单的理解为一个没有内容的占位标识，直到我们给结构体分配了内存，这个占位标识才变成了一个有长度的数组。\r\n看到这里，你会说，为什么要这样搞啊，把contents声明成一个指针，然后为它再分配一下内存不行么？就像下面一样。\r\n[cpp] view plain copy print?在CODE上查看代码片派生到我的代码片\r\nstruct line {  \r\n   int length;  \r\n   char *contents;  \r\n};  \r\n   \r\nint main(){  \r\n    int this_length=10;  \r\n    struct line *thisline = (struct line*)malloc (sizeof (struct line));  \r\n    thisline->contents = (char*) malloc(sizeof(char) * this_length );  \r\n    thisline->length = this_length;  \r\n    memset(thisline->contents, ''a'',this_length);  \r\n    return 0;  \r\n}  \r\n这不一样清楚吗？而且也没什么怪异难懂的东西。是的，这也是普遍的编程方式，代码是很清晰，也让人很容易理解。即然这样，那为什么要搞一个零长度的数组？有毛意义？！\r\n这个事情出来的原因是——我们想给一个结构体内的数据分配一个连续的内存！这样做的意义有两个好处：\r\n第一个意义是，方便内存释放。如果我们的代码是在一个给别人用的函数中，你在里面做了二次内存分配，并把整个结构体返回给用户。用户调用free可以释放结构体，但是用户并不知道这个结构体内的成员也需要free，所以你不能指望用户来发现这个事。所以，如果我们把结构体的内存以及其成员要的内存一次性分配好了，并返回给用户一个结构体指针，用户做一次free就可以把所有的内存也给释放掉。（读到这里，你一定子就觉得C++的虚函数会让这事容易和干净很多）\r\n第二个原因是，这样有利于访问速度。连续的内存有益于提高访问速度，也有益于减少内存碎片。（其实，我个人觉得也没多高了，反正你跑不了要用做偏移量的加法来寻址）\r\n我们来看看是怎么个连续的，用gdb的x命令来查看：(我们知道，用struct line {}中的那个char contents[]不占用结构体的内存，所以，struct line就只有一个int成员，4个字节，而我们还要为contents[]分配10个字节长度，所以，一共是14个字节)\r\n(gdb) x /14b thisline\r\n0x601010:       10     0       0       0      97      97      97     97\r\n0x601018:       97     97      97      97     97      97\r\n从上面的内存布局我们可以看到，前4个字节是 int length，后10个字节就是char contents[]。\r\n如果用指针的话，会变成这个样子：\r\n(gdb) x /16b thisline\r\n0x601010:       1      0       0       0      0       0       0      0\r\n0x601018:       32     16      96      0      0       0       0      0\r\n(gdb) x /10bthis->contents\r\n0x601020:       97     97      97      97     97      97      97     97\r\n0x601028:       97     97\r\n上面一共输出了四行内存，其中，\r\n·                                第一行前四个字节是 int length，第一行的后四个字节是对齐。\r\n·                                第二行是char* contents，64位系统指针8个长度，他的值是0×20 0×10 0×60 也就是0×601020。\r\n·                                第三行和第四行是char* contents指向的内容。\r\n从这里，我们看到，其中的差别——数组的原地就是内容，而指针的那里保存的是内容的地址。', 5, 1, NULL, 0);
INSERT INTO `article` (`id`, `title`, `formaltext`, `column`, `user_id`, `link`, `is_link`) VALUES
(8, 'TCP那些事（上）', 'TCP是一个巨复杂的协议，因为他要解决很多问题，而这些问题又带出了很多子问题和阴暗面。所以学习TCP本身是个比较痛苦的过程，但对于学习的过程却能让人有很多收获。关于TCP这个协议的细节，我还是推荐你去看W.Richard Stevens的《TCP/IP 详解 卷1：协议》（当然，你也可以去读一下RFC793以及后面N多的RFC）。另外，本文我会使用英文术语，这样方便你通过这些英文关键词来查找相关的技术文档。\r\n　　之所以想写这篇文章，目的有三个，\r\n一个是想锻炼一下自己是否可以用简单的篇幅把这么复杂的TCP协议描清楚的能力。\r\n另一个是觉得现在的好多程序员基本上不会认认真真地读本书，喜欢快餐文化，所以，希望这篇快餐文章可以让你对TCP这个古典技术有所了解，并能体会到软件设计中的种种难处。并且你可以从中有一些软件设计上的收获。\r\n最重要的希望这些基础知识可以让你搞清很多以前一些似是而非的东西，并且你能意识到基础的重要。\r\n　　所以，本文不会面面俱到，只是对TCP协议、算法和原理的科普。\r\n　　我本来只想写一个篇幅的文章的，但是TCP真TMD的复杂，比C++复杂多了，这30多年来，各种优化变种争论和修改。所以，写着写着就发现只有砍成两篇。\r\n上篇中，主要向你介绍TCP协议的定义和丢包时的重传机制。\r\n下篇中，重点介绍TCP的流迭、拥塞处理。\r\n　　废话少说，首先，我们需要知道TCP在网络OSI的七层模型中的第四层——Transport层，IP在第三层——Network层，ARP在第二层——Data Link层，在第二层上的数据，我们叫Frame，在第三层上的数据叫Packet，第四层的数据叫Segment。\r\n　　首先，我们需要知道，我们程序的数据首先会打到TCP的Segment中，然后TCP的Segment会打到IP的Packet中，然后再打到以太网Ethernet的Frame中，传到对端后，各个层解析自己的协议，然后把数据交给更高层的协议处理。\r\n　　TCP头格式\r\n　　接下来，我们来看一下TCP头的格式\r\nTCP头格式（图片来源）\r\n　　你需要注意这么几点：\r\nTCP的包是没有IP地址的，那是IP层上的事。但是有源端口和目标端口。\r\n一个TCP连接需要四个元组来表示是同一个连接（src_ip, src_port, dst_ip, dst_port）准确说是五元组，还有一个是协议。但因为这里只是说TCP协议，所以，这里我只说四元组。\r\n注意上图中的四个非常重要的东西：\r\nSequence Number是包的序号，用来解决网络包乱序（reordering）问题。\r\nAcknowledgement Number就是ACK——用于确认收到，用来解决不丢包的问题。\r\nWindow又叫Advertised-Window，也就是著名的滑动窗口（Sliding Window），用于解决流控的。\r\nTCP Flag ，也就是包的类型，主要是用于操控TCP的状态机的。\r\n　　关于其它的东西，可以参看下面的图示\r\n\r\n（图片来源）\r\n　　TCP的状态机\r\n　　其实，网络上的传输是没有连接的，包括TCP也是一样的。而TCP所谓的“连接”，其实只不过是在通讯的双方维护一个“连接状态”，让它看上去好像有连接一样。所以，TCP的状态变换是非常重要的。\r\n　　下面是：“TCP协议的状态机”（图片来源） 和 “TCP建链接”、“TCP断链接”、“传数据” 的对照图，我把两个图并排放在一起，这样方便在你对照着看。另外，下面这两个图非常非常的重要，你一定要记牢。（吐个槽：看到这样复杂的状态机，就知道这个协议有多复杂，复杂的东西总是有很多坑爹的事情，所以TCP协议其实也挺坑爹的）\r\n \r\n　　很多人会问，为什么建链接要3次握手，断链接需要4次挥手？\r\n对于建链接的3次握手，主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。也就上图中的 x 和 y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。\r\n对于4次挥手，其实你仔细看是2次，因为TCP是全双工的，所以，发送方和接收方都需要Fin和Ack。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。下图是双方同时断连接的示意图（你同样可以对照着TCP状态机看）：\r\n\r\n两端同时断连接（图片来源）\r\n　　另外，有几个事情需要注意一下：\r\n关于建连接时SYN超时。试想一下，如果server端接到了clien发的SYN后回了SYN-ACK后client掉线了，server端没有收到client回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server端如果在一定时间内没有收到的TCP会重发SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。\r\n关于SYN Flood攻击。一些恶意的人就为此制造了SYN Flood攻击——给服务器发了一个SYN后，就下线了，于是服务器需要默认等63s才会断开连接，这样，攻击者就可以把服务器的syn连接的队列耗尽，让正常的连接请求不能处理。于是，Linux下给了一个叫tcp_syncookies的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使你不在SYN队列中）。请注意，请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为，synccookies是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。\r\n关于ISN的初始化。ISN是不能hard code的，不然会出问题的——比如：如果连接建好后始终用1来做ISN，如果client发了30个segment过去，但是网络断了，于是 client重连，又用了1做ISN，但是之前连接的那些包到了，于是就被当成了新连接的包，此时，client的Sequence Number 可能是3，而Server端认为client端的这个号是30了。全乱了。RFC793中说，ISN会和一个假的时钟绑在一起，这个时钟会在每4微秒对ISN做加一操作，直到超过2^32，又从0开始。这样，一个ISN的周期大约是4.55个小时。因为，我们假设我们的TCP Segment在网络上的存活时间不会超过Maximum Segment Lifetime（缩写为MSL - Wikipedia语条），所以，只要MSL的值小于4.55小时，那么，我们就不会重用到ISN。\r\n关于 MSL 和 TIME_WAIT。通过上面的ISN的描述，相信你也知道MSL是怎么来的了。我们注意到，在TCP的状态图中，从TIME_WAIT状态到CLOSED状态，有一个超时设置，这个超时设置是 2*MSL（RFC793定义了MSL为2分钟，Linux设置成了30s）为什么要这有TIME_WAIT？为什么不直接给转成CLOSED状态呢？主要有两个原因：1）TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到Ack，就会触发被动端重发Fin，一来一去正好2个MSL，2）有足够的时间让这个连接不会跟后面的连接混在一起（你要知道，有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起）。你可以看看这篇文章《TIME_WAIT and its design implications for protocols and scalable client server systems》\r\n关于TIME_WAIT数量太多。从上面的描述我们可以知道，TIME_WAIT是个很重要的状态，但是如果在大并发的短链接下，TIME_WAIT 就会太多，这也会消耗很多系统资源。只要搜一下，你就会发现，十有八九的处理方式都是教你设置两个参数，一个叫tcp_tw_reuse，另一个叫tcp_tw_recycle的参数，这两个参数默认值都是被关闭的，后者recyle比前者resue更为激进，resue要温柔一些。另外，如果使用tcp_tw_reuse，必需设置tcp_timestamps=1，否则无效。这里，你一定要注意，打开这两个参数会有比较大的坑——可能会让TCP连接出一些诡异的问题（因为如上述一样，如果不等待超时重用连接的话，新的连接可能会建不上。正如官方文档上说的一样“It should not be changed without advice/request of technical experts”）。\r\n关于tcp_tw_reuse。官方文档上说tcp_tw_reuse 加上tcp_timestamps（又叫PAWS, for Protection Against Wrapped Sequence Numbers）可以保证协议的角度上的安全，但是你需要tcp_timestamps在两边都被打开（你可以读一下tcp_twsk_unique的源码 ）。我个人估计还是有一些场景会有问题。\r\n关于tcp_tw_recycle。如果是tcp_tw_recycle被打开了话，会假设对端开启了tcp_timestamps，然后会去比较时间戳，如果时间戳变大了，就可以重用。但是，如果对端是一个NAT网络的话（如：一个公司只用一个IP出公网）或是对端的IP被另一台重用了，这个事就复杂了。建链接的SYN可能就被直接丢掉了（你可能会看到connection time out的错误）（如果你想观摩一下Linux的内核代码，请参看源码 tcp_timewait_state_process）。\r\n关于tcp_max_tw_buckets。这个是控制并发的TIME_WAIT的数量，默认值是180000，如果超限，那么，系统会把多的给destory掉，然后在日志里打一个警告（如：time wait bucket table overflow），官网文档说这个参数是用来对抗DDoS攻击的。也说的默认值180000并不小。这个还是需要根据实际情况考虑。\r\n　　Again，使用tcp_tw_reuse和tcp_tw_recycle来解决TIME_WAIT的问题是非常非常危险的，因为这两个参数违反了TCP协议（RFC 1122） \r\n　　其实，TIME_WAIT表示的是你主动断连接，所以，这就是所谓的“不作死不会死”。试想，如果让对端断连接，那么这个破问题就是对方的了，呵呵。另外，如果你的服务器是于HTTP服务器，那么设置一个HTTP的KeepAlive有多重要（浏览器会重用一个TCP连接来处理多个HTTP请求），然后让客户端去断链接（你要小心，浏览器可能会非常贪婪，他们不到万不得已不会主动断连接）。\r\n　　数据传输中的Sequence Number\r\n　　下图是我从Wireshark中截了个我在访问coolshell.cn时的有数据传输的图给你看一下，SeqNum是怎么变的。（使用Wireshark菜单中的Statistics ->Flow Graph… ）\r\n\r\n　　你可以看到，SeqNum的增加是和传输的字节数相关的。上图中，三次握手后，来了两个Len:1440的包，而第二个包的SeqNum就成了1441。然后第一个ACK回的是1441，表示第一个1440收到了。\r\n　　注意：如果你用Wireshark抓包程序看3次握手，你会发现SeqNum总是为0，不是这样的，Wireshark为了显示更友好，使用了Relative SeqNum——相对序号，你只要在右键菜单中的protocol preference 中取消掉就可以看到“Absolute SeqNum”了\r\n　　TCP重传机制\r\n　　TCP要保证所有的数据包都可以到达，所以，必需要有重传机制。\r\n　　注意，接收端给发送端的Ack确认只会确认最后一个连续的包，比如，发送端发了1,2,3,4,5一共五份数据，接收端收到了1，2，于是回ack 3，然后收到了4（注意此时3没收到），此时的TCP会怎么办？我们要知道，因为正如前面所说的，SeqNum和Ack是以字节数为单位，所以ack的时候，不能跳着确认，只能确认最大的连续收到的包，不然，发送端就以为之前的都收到了。\r\n　　超时重传机制\r\n　　一种是不回ack，死等3，当发送方发现收不到3的ack超时后，会重传3。一旦接收方收到3后，会ack 回 4——意味着3和4都收到了。\r\n　　但是，这种方式会有比较严重的问题，那就是因为要死等3，所以会导致4和5即便已经收到了，而发送方也完全不知道发生了什么事，因为没有收到Ack，所以，发送方可能会悲观地认为也丢了，所以有可能也会导致4和5的重传。\r\n　　对此有两种选择：\r\n一种是仅重传timeout的包。也就是第3份数据。\r\n另一种是重传timeout后所有的数据，也就是第3，4，5这三份数据。\r\n　　这两种方式有好也有不好。第一种会节省带宽，但是慢，第二种会快一点，但是会浪费带宽，也可能会有无用功。但总体来说都不好。因为都在等timeout，timeout可能会很长（在下篇会说TCP是怎么动态地计算出timeout的）\r\n　　快速重传机制\r\n　　于是，TCP引入了一种叫Fast Retransmit 的算法，不以时间驱动，而以数据驱动重传。也就是说，如果，包没有连续到达，就ack最后那个可能被丢了的包，如果发送方连续收到3次相同的ack，就重传。Fast Retransmit的好处是不用等timeout了再重传。\r\n　　比如：如果发送方发出了1，2，3，4，5份数据，第一份先到送了，于是就ack回2，结果2因为某些原因没收到，3到达了，于是还是ack回2，后面的4和5都到了，但是还是ack回2，因为2还是没有收到，于是发送端收到了三个ack=2的确认，知道了2还没有到，于是就马上重转2。然后，接收端收到了2，此时因为3，4，5都收到了，于是ack回6。示意图如下：\r\n\r\n　　Fast Retransmit只解决了一个问题，就是timeout的问题，它依然面临一个艰难的选择，就是重转之前的一个还是重装所有的问题。对于上面的示例来说，是重传#2呢还是重传#2，#3，#4，#5呢？因为发送端并不清楚这连续的3个ack(2)是谁传回来的？也许发送端发了20份数据，是#6，#10，#20传来的呢。这样，发送端很有可能要重传从2到20的这堆数据（这就是某些TCP的实际的实现）。可见，这是一把双刃剑。\r\n　　SACK 方法\r\n　　另外一种更好的方式叫：Selective Acknowledgment (SACK)（参看RFC 2018），这种方式需要在TCP头里加一个SACK的东西，ACK还是Fast Retransmit的ACK，SACK则是汇报收到的数据碎版。参看下图：\r\n\r\n　　这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到。于是就优化了Fast Retransmit的算法。当然，这个协议需要两边都支持。在 Linux下，可以通过tcp_sack参数打开这个功能（Linux 2.4后默认打开）。\r\n　　这里还需要注意一个问题——接收方Reneging，所谓Reneging的意思就是接收方有权把已经报给发送端SACK里的数据给丢了。这样干是不被鼓励的，因为这个事会把问题复杂化了，但是，接收方这么做可能会有些极端情况，比如要把内存给别的更重要的东西。所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Time-Out，如果后续的ACK没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为Ack。\r\n　　注意：SACK会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。详细的东西请参看《TCP SACK的性能权衡》\r\n　　Duplicate SACK – 重复收到数据的问题\r\n　　Duplicate SACK又称D-SACK，其主要使用了SACK来告诉发送方有哪些数据被重复接收了。RFC-2833里有详细描述和示例。下面举几个例子（来源于RFC-2833）\r\n　　D-SACK使用了SACK的第一个段来做标志，\r\n如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK\r\n如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK\r\n　　示例一：ACK丢包\r\n　　下面的示例中，丢了两个ACK，所以，发送端重传了第一个数据包（3000-3499），于是接收端发现重复收到，于是回了一个SACK=3000-3500，因为ACK都到了4000意味着收到了4000之前的所有数据，所以这个SACK就是D-SACK——旨在告诉发送端我收到了重复的数据，而且我们的发送端还知道，数据包没有丢，丢的是ACK包。\r\nTransmitted  Received    ACK Sent\r\n\r\nSegment      Segment     (Including SACK Blocks)\r\n\r\n3000-3499    3000-3499   3500 (ACK dropped)\r\n\r\n3500-3999    3500-3999   4000 (ACK dropped)\r\n\r\n3000-3499    3000-3499   4000, SACK=3000-3500\r\n\r\n                                    ---------\r\n　　 示例二，网络延误\r\n　　下面的示例中，网络包（1000-1499）被网络给延误了，导致发送方没有收到ACK，而后面到达的三个包触发了“Fast Retransmit算法”，所以重传，但重传时，被延误的包又到了，所以，回了一个SACK=1000-1500，因为ACK已到了3000，所以，这个SACK是D-SACK——标识收到了重复的包。\r\n　　这个案例下，发送端知道之前因为“Fast Retransmit算法”触发的重传不是因为发出去的包丢了，也不是因为回应的ACK包丢了，而是因为网络延时了。\r\nTransmitted    Received    ACK Sent\r\n\r\nSegment        Segment     (Including SACK Blocks)\r\n\r\n500-999        500-999     1000\r\n\r\n1000-1499      (delayed)\r\n\r\n1500-1999      1500-1999   1000, SACK=1500-2000\r\n\r\n2000-2499      2000-2499   1000, SACK=1500-2500\r\n\r\n2500-2999      2500-2999   1000, SACK=1500-3000\r\n\r\n1000-1499      1000-1499   3000\r\n\r\n               1000-1499   3000, SACK=1000-1500\r\n\r\n                                      ---------\r\n　　可见，引入了D-SACK，有这么几个好处：\r\n　　1）可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。\r\n　　2）是不是自己的timeout太小了，导致重传。\r\n　　3）网络上出现了先发的包后到的情况（又称reordering）\r\n　　4）网络上是不是把我的数据包给复制了。\r\n　　知道这些东西可以很好得帮助TCP了解网络情况，从而可以更好的做网络上的流控。\r\n　　Linux下的tcp_dsack参数用于开启这个功能（Linux 2.4后默认打开）\r\n　　好了，上篇就到这里结束了。如果你觉得我写得还比较浅显易懂，那么，欢迎移步看下篇《TCP的那些事（下）》', 5, 1, NULL, 0),
(9, 'TCP那些事（下）', '这篇文章是下篇，所以如果你对TCP不熟悉的话，还请你先看看上篇《TCP的那些事儿（上）》 上篇中，我们介绍了TCP的协议头、状态机、数据重传中的东西。但是TCP要解决一个很大的事，那就是要在一个网络根据不同的情况来动态调整自己的发包的速度，小则让自己的连接更稳定，大则让整个网络更稳定。在你阅读下篇之前，你需要做好准备，本篇文章有好些算法和策略，可能会引发你的各种思考，让你的大脑分配很多内存和计算资源，所以，不适合在厕所中阅读。\r\n\r\nTCP的RTT算法\r\n从前面的TCP的重传机制我们知道Timeout的设置对于重传非常重要，\r\n\r\n设长了，重发就慢，没有效率，性能差；\r\n设短了，重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。\r\n而且，这个超时时间在不同的网络的情况下，有不同的时间，根本没有办法设置一个死的。只能动态地设置。 为了动态地设置，TCP引入了RTT——Round Trip Time，也就是一个数据包从发出去到回来的时间。这样发送端就大约知道需要多少的时间，从而可以方便地设置Timeout——RTO（Retransmission TimeOut），以让我们的重传机制更高效。 听起来似乎很简单，好像就是在发送端发包时记下t0，然后接收端再把这个ack回来时再记一个t1，于是RTT = t1 – t0。没那么简单，这只是一个采样，不能代表普遍情况。\r\n\r\n\r\n经典算法\r\nRFC793 中定义的经典算法是这样的： 1）首先，先采样RTT，记下最近好几次的RTT值。 2）然后做平滑计算SRTT – Smoothed RTT。公式为：（其中的 α 取值在0.8 到 0.9之间，这个算法英文叫Exponential weighted moving average，中文叫：加权移动平均） SRTT = ( α * SRTT ) + ((1- α) * RTT) 3）开始计算RTO。公式如下： RTO = min [ UBOUND,  max [ LBOUND,   (β * SRTT) ]  ] 其中：\r\n\r\nUBOUND是最大的timeout时间，上限值\r\nLBOUND是最小的timeout时间，下限值\r\nβ 值一般在1.3到2.0之间。\r\nKarn / Partridge 算法\r\n但是上面的这个算法在重传的时候会出有一个终极问题——你是用第一次的时间和ack回来的时候做RTT样本，还是用重传的时间和ACK的时间做RTT样本？这个问题无论你先那头都是按下葫芦起了瓢。 如下图所示：\r\n\r\n情况（a）是ack没回来，所发重传。如果你计算第一次发送和ACK的时间，那么，明显算大了。\r\n情况（b）是ack回来慢了，重传不一会，之前ACK就回来了。如果你是算重传的时间和ACK回来的时间，就会短了。\r\n所以1987年的时候，搞了一个叫Karn / Partridge Algorithm，这个算法的最大特点是——忽略重传，不把重传的RTT做采样（你看，你不需要去解决不存在的问题）。但是，这样一来，又会引发一个大BUG——如果在某一时间，网络闪动，突然变慢了，产生了比较大的延时，这个延时导致要重转所有的包（因为之前的RTO很小），于是，因为重转的不算，所以，RTO就不会被更新，这是一个灾难。 于是Karn算法用了一个取巧的方式——只要一发生重传，就对现有的RTO值翻倍（这就是所谓的 Exponential backoff）\r\n\r\nJacobson / Karels 算法\r\n前面两种算法用的都是“加权移动平均”，这种方法最大的毛病就是如果RTT有一个大的波动的话，很难被发现，因为被平滑掉了。所以，1988年，又有人推出来了一个新的算法，这个算法叫Jacobson / Karels Algorithm（参看RFC6289）。这个算法引入了最新的RTT的采样和平滑过的SRTT的差距做因子来计算。 公式如下：（其中的DevRTT是Deviation RTT的意思） SRTT = SRTT + α (RTT – SRTT) DevRTT = (1-β)*DevRTT + β*(|RTT-SRTT|) RTO= µ * SRTT + ∂ *DevRTT （其中：在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4 ——这就是算法中的“调得一手好参数”，nobody knows why, it just works…） 最后的这个算法在被用在今天的TCP协议中（Linux的源代码在：tcp_rtt_estimator）。\r\n\r\nTCP滑动窗口\r\n需要说明一下，如果你不了解TCP的滑动窗口这个事，你等于不了解TCP协议。我们都知道，TCP必需要解决的可靠传输以及包乱续的问题，所以，TCP必需要知道网络实际的数据处理带宽或是数据处理速度，这样才不会引起网络拥塞，导致丢包。所以，TCP引入了一些技术和设计来做网络流控，Sliding Window是其中一个技术。 前面我们说过，TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 为了说明滑动窗口，我们需要先看一下TCP缓冲区的一些数据结构：上图中，我们可以看到：\r\n\r\n接收端LastByteRead指向了TCP缓冲区中读到的位置，NextByteExpected指向的地方是收到的连续包的最后一个位置，LastByteRcved指向的是收到的包的最后一个位置，我们可以看到中间有些数据还没有到达，所以有数据空白区。\r\n发送端的LastByteAcked指向了被接收端Ack过的位置（表示成功发送确认），LastByteSent表示发出去了，但还没有收到成功确认的Ack，LastByteWritten指向的是上层应用正在写的地方。\r\n于是：\r\n\r\n接收端在给发送端回ACK中会汇报自己的AdvertisedWindow = MaxRcvBuffer – LastByteRcvd – 1;\r\n而发送方会根据这个窗口来控制发送数据的大小，以保证接收方可以处理。\r\n下面我们来看一下发送方的滑动窗口示意图：\r\n\r\n（图片来源）\r\n\r\n上图中分成了四个部分，分别是：（其中那个黑模型就是滑动窗口）\r\n\r\n#1已收到ack确认的数据。\r\n#2发还没收到ack的。\r\n#3在窗口中还没有发出的（接收方还有空间）。\r\n#4窗口以外的数据（接收方没空间）\r\n下面是个滑动后的示意图（收到36的ack，并发出了46-51的字节）：下面我们来看一个接受端控制发送端的图示：\r\n\r\n（图片来源）\r\n\r\nZero Window\r\n上图，我们可以看到一个处理缓慢的Server是怎么把TCP Sliding Window给降成0的。此时，你一定会问，如果Window变成0了，TCP会怎么样？是不是发送端就不发数据了？是的，发送端就不发数据了，你可以想像成“Window Closed”，那你一定还会问，如果发送端不发数据了，接收方一会儿Window size 可用了，怎么通知发送端呢？\r\n\r\n解决这个问题，TCP使用了Zero Window Probe技术，缩写为ZWP，也就是说，发送端会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（依实现而定）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。\r\n\r\n注意：只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。（关于这方面的攻击，大家可以移步看一下Wikipedia的SockStress词条）\r\n\r\n另外，Wireshark中，你可以使用tcp.analysis.zero_window来过滤包，然后使用右键菜单里的follow TCP stream，你可以看到ZeroWindowProbe及ZeroWindowProbeAck的包。\r\n\r\nSilly Window Syndrome\r\nSilly Window Syndrome翻译成中文就是“糊涂窗口综合症”。正如你上面看到的一样，如果我们的接收方太忙了，来不及取走Receive Windows里的数据，那么，就会导致发送方越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的window，而我们的发送方会义无反顾地发送这几个字节。 要知道，我们的TCP+IP头有40个字节，为了几个字节，要达上这么大的开销，这太不经济了。 另外，你需要知道网络上有个MTU，对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是所谓的MSS（Max Segment Size）注意，TCP的RFC定义这个MSS的默认值是536，这是因为 RFC 791里说了任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU）。如果你的网络包可以塞满MTU，那么你可以用满整个带宽，如果不能，那么你就会浪费带宽。（大于MTU的包有两种结局，一种是直接被丢了，另一种是会被重新分块打包发送） 你可以想像成一个MTU就相当于一个飞机的最多可以装的人，如果这飞机里满载的话，效率最高，如果只有一个人的话，无疑成本增加了。所以，Silly Windows Syndrome这个现像就像是你本来可以坐200人的飞机里只做了一两个人。 要解决这个问题也不难，就是避免对小的window size做出响应，直到有足够大的window size再响应，这个思路可以同时实现在sender和receiver两端。\r\n\r\n如果这个问题是由Receiver端引起的，那么就会使用 David D Clark’s 方案。在receiver端，如果收到的数据导致window size小于某个值，可以直接ack(0)回sender，这样就把window给关闭了，也阻止了sender再发数据过来，等到receiver端处理了一些数据后windows size 大于等于了MSS，或者，receiver buffer有一半为空，就可以把window打开让send 发送数据过来。\r\n如果这个问题是由Sender端引起的，那么就会使用著名的 Nagle’s algorithm。这个算法的思路也是延时处理，他有两个主要的条件（更多的条件可以看一下tcp_nagle_check函数）：1）要等到 Window Size>=MSS 或是 Data Size >=MSS，2）等待时间或是超时200ms，这两个条件有一个满足，他才会发数据，否则就是在攒数据。\r\n另外，Nagle算法默认是打开的，所以，对于一些需要小包场景的程序——比如像telnet或ssh这样的交互性比较强的程序，你需要关闭这个算法。你可以在Socket设置TCP_NODELAY选项来关闭这个算法\r\n\r\n1\r\nsetsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&value,sizeof(int));\r\n另外，网上有些文章说TCP_CORK的socket option是也关闭Nagle算法，这个还不够准确。TCP_CORK是禁止小包发送，而没有禁止小包发送，只是禁止了大量的小包发送。最好不要两个选项都设置。 老实说，我觉得Nagle算法其实只加了个延时，没有别的什么，我觉得最好还是把他关闭，然后由自己的应用层来控制数据，我个觉得不应该什么事都去依赖内核算法。\r\n\r\nTCP的拥塞处理 - Congestion Handling\r\n上面我们知道了，TCP通过Sliding Window来做流控（Flow Control），但是TCP觉得这还不够，因为Sliding Window需要依赖于连接的发送端和接收端，其并不知道网络中间发生了什么。TCP的设计者觉得，一个伟大而牛逼的协议仅仅做到流控并不够，因为流控只是网络模型4层以上的事，TCP的还应该更聪明地知道整个网络上的事。 具体一点，我们知道TCP通过一个timer采样了RTT并计算RTO，但是，如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。这是一个灾难。 所以，TCP不能忽略网络上发生的事情，而无脑地一个劲地重发数据，对网络造成更大的伤害。对此TCP的设计理念是：TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了。 关于拥塞控制的论文请参看《Congestion Avoidance and Control》(PDF) 拥塞控制主要是四个算法：1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复。这四个算法不是一天都搞出来的，这个四算法的发展经历了很多时间，到今天都还在优化中。 备注:\r\n\r\n1988年，TCP-Tahoe 提出了1）慢启动，2）拥塞避免，3）拥塞发生时的快速重传\r\n1990年，TCP Reno 在Tahoe的基础上增加了4）快速恢复\r\n慢热启动算法 – Slow Start\r\n首先，我们来看一下TCP的慢热启动。慢启动的意思是，刚刚加入网络的连接，一点一点地提速，不要一上来就像那些特权车一样霸道地把路占满。新同学上高速还是要慢一点，不要把已经在高速上的秩序给搞乱了。   慢启动的算法如下(cwnd全称Congestion Window)：\r\n\r\n1）连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。\r\n\r\n2）每当收到一个ACK，cwnd++; 呈线性上升\r\n\r\n3）每当过了一个RTT，cwnd = cwnd*2; 呈指数让升\r\n\r\n4）还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）\r\n\r\n所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程。这里，我需要提一下的是一篇Google的论文《An Argument for Increasing TCP’s Initial Congestion Window》Linux 3.0后采用了这篇论文的建议——把cwnd 初始化成了 10个MSS。 而Linux 3.0以前，比如2.6，Linux采用了RFC3390，cwnd是跟MSS的值来变的，如果MSS< 1095，则cwnd = 4；如果MSS>2190，则cwnd=2；其它情况下，则是3。\r\n\r\n 拥塞避免算法 - Congestion Avoidance\r\n前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：\r\n\r\n1）收到一个ACK时，cwnd = cwnd + 1/cwnd\r\n\r\n2）当每过一个RTT时，cwnd = cwnd + 1\r\n\r\n这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。\r\n\r\n拥塞状态算法\r\n前面我们说过，当丢包的时候，会有两种情况：\r\n\r\n1）等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。\r\n\r\nsshthresh =  cwnd /2\r\ncwnd 重置为 1\r\n进入慢启动过程\r\n2）Fast Retransmit算法，也就是在收到3个duplicate ACK时就开启重传，而不用等到RTO超时。\r\n\r\nTCP Tahoe的实现和RTO超时一样。\r\nTCP Reno的实现是：\r\ncwnd = cwnd /2\r\nsshthresh = cwnd\r\n进入快速恢复算法——Fast Recovery\r\n上面我们可以看到RTO超时后，sshthresh会变成cwnd的一半，这意味着，如果cwnd<=sshthresh时出现的丢包，那么TCP的sshthresh就会减了一半，然后等cwnd又很快地以指数级增涨爬到这个地方时，就会成慢慢的线性增涨。我们可以看到，TCP是怎么通过这种强烈地震荡快速而小心得找到网站流量的平衡点的。\r\n\r\n快速恢复算法 – Fast Recovery\r\nTCP Reno 这个算法定义在RFC5681。快速重传和快速恢复算法一般同时使用。快速恢复算法是认为，你还有3个Duplicated Acks说明网络也不那么糟糕，所以没有必要像RTO超时那么强烈。 注意，正如前面所说，进入Fast Recovery之前，cwnd 和 sshthresh已被更新：\r\n\r\ncwnd = cwnd /2\r\nsshthresh = cwnd\r\n然后，真正的Fast Recovery算法如下：\r\n\r\ncwnd = sshthresh  + 3 * MSS （3的意思是确认有3个数据包被收到了）\r\n重传Duplicated ACKs指定的数据包\r\n如果再收到 duplicated Acks，那么cwnd = cwnd +1\r\n如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。\r\n如果你仔细思考一下上面的这个算法，你就会知道，上面这个算法也有问题，那就是——它依赖于3个重复的Acks。注意，3个重复的Acks并不代表只丢了一个数据包，很有可能是丢了好多包。但这个算法只会重传一个，而剩下的那些包只能等到RTO超时，于是，进入了恶梦模式——超时一个就减半一下，多个超时会超成TCP的传输速度呈级数下降，而且也不会触发Fast Recovery算法了。 通常来说，正如我们前面所说的，SACK或D-SACK的方法可以让Fast Recovery或Sender在做决定时更聪明一些，但是并不是所有的TCP的实现都支持SACK（SACK需要两端都支持），所以，需要一个没有SACK的解决方案。而通过SACK进行拥塞控制的算法是FACK（后面会讲） TCP New Reno 于是，1995年，TCP New Reno（参见 RFC 6582 ）算法提出来，主要就是在没有SACK的支持下改进Fast Recovery算法的——\r\n\r\n当sender这边收到了3个Duplicated Acks，进入Fast Retransimit模式，开发重传重复Acks指示的那个包。如果只有这一个包丢了，那么，重传这个包后回来的Ack会把整个已经被sender传输出去的数据ack回来。如果没有的话，说明有多个包丢了。我们叫这个ACK为Partial ACK。\r\n一旦Sender这边发现了Partial ACK出现，那么，sender就可以推理出来有多个包被丢了，于是乎继续重传sliding window里未被ack的第一个包。直到再也收不到了Partial Ack，才真正结束Fast Recovery这个过程\r\n我们可以看到，这个“Fast Recovery的变更”是一个非常激进的玩法，他同时延长了Fast Retransmit和Fast Recovery的过程。\r\n\r\n算法示意图\r\n下面我们来看一个简单的图示以同时看一下上面的各种算法的样子：\r\n\r\nFACK算法\r\nFACK全称Forward Acknowledgment 算法，论文地址在这里（PDF）Forward Acknowledgement: Refining TCP Congestion Control 这个算法是其于SACK的，前面我们说过SACK是使用了TCP扩展字段Ack了有哪些数据收到，哪些数据没有收到，他比Fast Retransmit的3 个duplicated acks好处在于，前者只知道有包丢了，不知道是一个还是多个，而SACK可以准确的知道有哪些包丢了。 所以，SACK可以让发送端这边在重传过程中，把那些丢掉的包重传，而不是一个一个的传，但这样的一来，如果重传的包数据比较多的话，又会导致本来就很忙的网络就更忙了。所以，FACK用来做重传过程中的拥塞流控。\r\n\r\n这个算法会把SACK中最大的Sequence Number 保存在snd.fack这个变量中，snd.fack的更新由ack带秋，如果网络一切安好则和snd.una一样（snd.una就是还没有收到ack的地方，也就是前面sliding window里的category #2的第一个地方）\r\n然后定义一个awnd = snd.nxt – snd.fack（snd.nxt指向发送端sliding window中正在要被发送的地方——前面sliding windows图示的category#3第一个位置），这样awnd的意思就是在网络上的数据。（所谓awnd意为：actual quantity of data outstanding in the network）\r\n如果需要重传数据，那么，awnd = snd.nxt – snd.fack + retran_data，也就是说，awnd是传出去的数据 + 重传的数据。\r\n然后触发Fast Recovery 的条件是： ( ( snd.fack – snd.una ) > (3*MSS) ) || (dupacks == 3) ) 。这样一来，就不需要等到3个duplicated acks才重传，而是只要sack中的最大的一个数据和ack的数据比较长了（3个MSS），那就触发重传。在整个重传过程中cwnd不变。直到当第一次丢包的snd.nxt<=snd.una（也就是重传的数据都被确认了），然后进来拥塞避免机制——cwnd线性上涨。\r\n我们可以看到如果没有FACK在，那么在丢包比较多的情况下，原来保守的算法会低估了需要使用的window的大小，而需要几个RTT的时间才会完成恢复，而FACK会比较激进地来干这事。 但是，FACK如果在一个网络包会被 reordering的网络里会有很大的问题。\r\n\r\n其它拥塞控制算法简介\r\nTCP Vegas 拥塞控制算法\r\n这个算法1994年被提出，它主要对TCP Reno 做了些修改。这个算法通过对RTT的非常重的监控来计算一个基准RTT。然后通过这个基准RTT来估计当前的网络实际带宽，如果实际带宽比我们的期望的带宽要小或是要多的活，那么就开始线性地减少或增加cwnd的大小。如果这个计算出来的RTT大于了Timeout后，那么，不等ack超时就直接重传。（Vegas 的核心思想是用RTT的值来影响拥塞窗口，而不是通过丢包） 这个算法的论文是《TCP Vegas: End to End Congestion Avoidance on a Global Internet》这篇论文给了Vegas和 New Reno的对比：  关于这个算法实现，你可以参看Linux源码：/net/ipv4/tcp_vegas.h， /net/ipv4/tcp_vegas.c\r\n\r\nHSTCP(High Speed TCP) 算法\r\n这个算法来自RFC 3649（Wikipedia词条）。其对最基础的算法进行了更改，他使得Congestion Window涨得快，减得慢。其中：\r\n\r\n拥塞避免时的窗口增长方式： cwnd = cwnd + α(cwnd) / cwnd\r\n丢包后窗口下降方式：cwnd = (1- β(cwnd))*cwnd\r\n注：α(cwnd)和β(cwnd)都是函数，如果你要让他们和标准的TCP一样，那么让α(cwnd)=1，β(cwnd)=0.5就可以了。 对于α(cwnd)和β(cwnd)的值是个动态的变换的东西。 关于这个算法的实现，你可以参看Linux源码：/net/ipv4/tcp_highspeed.c\r\n\r\n TCP BIC 算法\r\n2004年，产内出BIC算法。现在你还可以查得到相关的新闻《Google：美科学家研发BIC-TCP协议 速度是DSL六千倍》 BIC全称Binary Increase Congestion control，在Linux 2.6.8中是默认拥塞控制算法。BIC的发明者发这么多的拥塞控制算法都在努力找一个合适的cwnd – Congestion Window，而且BIC-TCP的提出者们看穿了事情的本质，其实这就是一个搜索的过程，所以BIC这个算法主要用的是Binary Search——二分查找来干这个事。 关于这个算法实现，你可以参看Linux源码：/net/ipv4/tcp_bic.c\r\n\r\nTCP WestWood算法\r\nwestwood采用和Reno相同的慢启动算法、拥塞避免算法。westwood的主要改进方面：在发送端做带宽估计，当探测到丢包时，根据带宽值来设置拥塞窗口、慢启动阈值。 那么，这个算法是怎么测量带宽的？每个RTT时间，会测量一次带宽，测量带宽的公式很简单，就是这段RTT内成功被ack了多少字节。因为，这个带宽和用RTT计算RTO一样，也是需要从每个样本来平滑到一个值的——也是用一个加权移平均的公式。 另外，我们知道，如果一个网络的带宽是每秒可以发送X个字节，而RTT是一个数据发出去后确认需要的时候，所以，X * RTT应该是我们缓冲区大小。所以，在这个算法中，ssthresh的值就是est_BD * min-RTT(最小的RTT值)，如果丢包是Duplicated ACKs引起的，那么如果cwnd > ssthresh，则 cwin = ssthresh。如果是RTO引起的，cwnd = 1，进入慢启动。   关于这个算法实现，你可以参看Linux源码： /net/ipv4/tcp_westwood.c\r\n\r\n其它\r\n更多的算法，你可以从Wikipedia的 TCP Congestion Avoidance Algorithm 词条中找到相关的线索\r\n\r\n 后记\r\n好了，到这里我想可以结束了，TCP发展到今天，里面的东西可以写上好几本书。本文主要目的，还是把你带入这些古典的基础技术和知识中，希望本文能让你了解TCP，更希望本文能让你开始有学习这些基础或底层知识的兴趣和信心。\r\n\r\n当然，TCP东西太多了，不同的人可能有不同的理解，而且本文可能也会有一些荒谬之言甚至错误，还希望得到您的反馈和批评。\r\n\r\n（全文完）', 4, 1, NULL, 0);
INSERT INTO `article` (`id`, `title`, `formaltext`, `column`, `user_id`, `link`, `is_link`) VALUES
(10, '无插件Vim编程技巧', '相信大家看过《简明 Vim 教程》也玩了《Vim 大冒险》的游戏了，相信大家对 Vim 都有一个好的入门了。我在这里把我日常用 Vim 编程的一些技巧列出来给大家看看，希望对大家有用，另外，也是一个抛砖引玉的过程，也希望大家把你们的技巧跟贴一下，我会更新到这篇文章中。另外，这篇文章里的这些技巧全都是 vim 原生态的，不需要你安装什么插件。我的 Vim 的版本是 7.2。\r\n\r\n　　浏览代码\r\n\r\n　　首先，我们先从浏览代码开始。有时候，我们需要看多个文件，所以，传统的做法是，我们开多个 tty 终端，每个 tty 里用 Vim 打开一个文件，然后来回切换。这很没有什么效率。我们希望在一个 Vim 里打开多个文件，甚至浏览程序目录。\r\n\r\n　　浏览目录的命令很简单：（你也可以直接 vim 一个目录）\r\n\r\n:E\r\n\r\n　　注意，是大写。于是，你会看到下面这样的界面：\r\n\r\n\r\n\r\n　　这个界面中，你可以用 j, k 键上下移动，然后回车，进入一个目录，或是找开一个文件。你可以看到上面有一堆命令：\r\n\r\n【 – 】 到上级目录\r\n【D】删除文件（大写）\r\n【R】改文件名（大写）\r\n【s】对文件排序（小写）\r\n【x】执行文件\r\n　　当然，打开的文件会把现有已打开的文件给冲掉——也就是说你只看到了一个文件。\r\n\r\n　　如果你要改变当前浏览的目录，或是查看当前浏览的目录，你可以使用和 shell 一样的命令：\r\n\r\n:cd <dir> – 改变当前目录\r\n\r\n:pwd  - 查看当前目录\r\n\r\n　　缓冲区\r\n\r\n　　其实，你用:E 浏览打开的文件都没有被关闭，这些文件都在缓冲区中。你可以用下面的命令来查看缓冲区：\r\n\r\n:ls\r\n\r\n　　于是，在你的 Vim 下，你会看到如下界面：\r\n\r\n\r\n\r\n　　你可以看到 Vim 打开了四个文件，编号是4，5，6，7，如果你要切换打开的文件，这个时候，你不要按回车（按了也没事，只不过按了就看不到:ls 输出的 buffer 列表了），你可以使用下面的命令切换文件（buffer 后面的 4 表示切到 4 号文件也就是 src/http/ngx_http.c）：\r\n\r\n:buffer 4\r\n\r\n　　或是：\r\n\r\n:buffer src/http/ngx_http.c\r\n\r\n　　注意，\r\n\r\n你可以像在 Shell 中输入命令按 Tab 键补全一样补全 Vim 的命令。\r\n也可以用像 gdb 一样用最前面的几个字符，只要没有冲突。如：buff\r\n　　你还可以动用如下命令，快速切换：\r\n\r\n:bnext      缩写 :bn\r\n\r\n:bprevious   缩写 :bp\r\n\r\n:blast  缩写 :bl\r\n\r\n:bfirst 缩写 :bf\r\n\r\n　　上图中，我们还可以看到 5 有一个%a，这表示当前文件，相关的标记如下：\r\n\r\n　　- （非活动的缓冲区）\r\n\r\n　　a （当前被激活缓冲区）\r\n\r\n　　h （隐藏的缓冲区）\r\n\r\n　　% （当前的缓冲区）\r\n\r\n　　# （交换缓冲区）\r\n\r\n　　= （只读缓冲区）\r\n\r\n　　+ （已经更改的缓冲区）\r\n\r\n　　窗口分屏浏览\r\n\r\n　　相信你在《Vim 的窗口分屏》一文中，你已经知道了怎么拆分窗口了。其实，我更多的不是用拆分窗口的命令，而是用浏览文件的命令来分隔窗口。如：\r\n\r\n　　把当前窗口上下分屏，并在下面进行目录浏览：\r\n\r\n:He   全称为 :Hexplore  （在下边分屏浏览目录）\r\n\r\n　　如果你要在上面，你就在 :He 后面加个 !，\r\n\r\n:He!  （在上分屏浏览目录）\r\n\r\n　　如果你要左右分屏的话，你可以这样：\r\n\r\n:Ve 全称为 :Vexplore （在左边分屏间浏览目录，要在右边则是 :Ve!）\r\n\r\n　　下图是分别用:He 和 :Ve 搞出来的同时看三个文件：\r\n\r\nhttp://coolshell.cn//wp-content/uploads/2014/03/WindowsExplorer.png\r\n\r\n　　在分屏间的跳转和切换在《Vim 的窗口分屏》一文中提过了：先按 Ctrl + W，然后按方向键：h j k l\r\n\r\n　　分屏同步移动\r\n\r\n　　要让两个分屏中的文件同步移动，很简单，你需要到需要同步移动的两个屏中都输入如下命令（相当于使用“铁锁连环”）：\r\n\r\n:set scb\r\n\r\n　　如果你需要解开，那么就输入下面的命令：\r\n\r\n:set scb!\r\n\r\n　　注：set scb 是 set scrollbind 的简写。\r\n\r\n　　Tab 页浏览目录\r\n\r\n　　分屏可能会让你不爽，你可能更喜欢像 Chrome 这样的分页式的浏览，那么你可以用下面的命令：\r\n\r\n:Te  全称是 :Texplorer\r\n\r\n　　下图中，你可以看到我用 Te 命令打开了三页，就在顶端我们可以可以看到有三页，其中第一页 Tab 上的数字 3 表示那一页有 3 个文件。\r\n\r\n\r\n\r\n　　我们要在多个 Tabe 页中切换，在 normal 模式下，你可以使用下面三个按键（注意没有冒号）：\r\n\r\ngt   – 到下一个页\r\n\r\ngT  - 到前一个页\r\n\r\n{i} gt   – i 是数字，到指定页，比如：5 gt 就是到第 5 页\r\n\r\n　　你可以以使用 【:tabm {n}】来切换 Tab 页。\r\n\r\n　　gvim 应该是：Ctrl+PgDn 和 Ctrl+PgUp 来在各个页中切换。\r\n\r\n　　如果你想看看你现在打开的窗口和 Tab 的情况，你可以使用下面的命令：\r\n\r\n:tabs\r\n\r\n　　于是你可以看到：\r\n\r\n\r\n\r\n　　使用如下命令可以关闭 tab：（当然，我更喜欢使用传统的:q, :wq 来关闭）\r\n\r\n:tabclose [i] – 如果后面指定了数字，那就关闭指定页，如果没有就关闭当前页\r\n\r\n　　最后提一下，如果你在 Shell 命令行下，你可以使用 vim 的 -p 参数来用 Tab 页的方式打开多个文件，比如：\r\n\r\nvim -p cool.cpp shell.cpp haoel.cpp\r\n\r\nvim -p *.cpp\r\n\r\n　　保存会话\r\n\r\n　　如果你用 Tab 或 Window 打开了好些文件的文件，还设置了各种滚屏同步，或是行号……，那么，你可以用下面的命令来保存会话：（你有兴趣你可以看看你的 mysession.vim 文件内容，也就是一个批处理文件）\r\n\r\n:mksession ~/.mysession.vim\r\n\r\n　　如果文件重复，vim 默认会报错，如果你想强行写入的话，你可以在 mksession 后加! ：\r\n\r\n:mksession! ~/.mysession.vim\r\n\r\n　　于是下次，你可以这样打开这个会话：\r\n\r\nvim -S ~/.mysession.vim\r\n\r\n　　保存完会话后，你也没有必要一个一个 Tab/Windows 的去 Close。你可以简单地使用：\r\n\r\n:qa   – 退出全部 \r\n\r\n:wqa  -保存全部并退出全部\r\n\r\n　　Quickfix\r\n\r\n　　假如我们有一个 hello.cpp 文件和一个 makefile，于是我们可以直接在 vim 下输入 :make ， 于是就可以 make 这个 hello.cpp 文件，如果出错了，我们需要按回车返回，这个时候，我们可以使用下面的命令来把出错显到在 vim 的分屏中：\r\n\r\n:cw\r\n\r\n　　于是，就会出现下面右边的那个样子：（是不是看上去和我一样很帅？）\r\n\r\n\r\n\r\n　　上图中左边是我的 makefile，右边是我的错误百出的源代码，右边下面是 quickfix 窗屏。你可以看到 quickfix 窗屏指向的第一个错误已经定位到我们相就错误的文件行上了。\r\n\r\n　　你可以使用像浏览文件那样用j, k 在 quckfix 窗屏中上下移动到相应的错误上然后按回车，然后就可以在上面的窗屏里定位到相应的源文件的代码行。但是，如果是这样的话， 你要定位下一条错误还得用 Ctrl +W 回到 quickfix 屏中来然后重复来过。\r\n\r\n　　你可以使用下面的命令而不用回到 quickfix 中来：\r\n\r\n:cp 跳到上一个错误\r\n\r\n:cn 跳到下一个错误\r\n\r\n:cl 列出所有错误\r\n\r\n:cc 显示错误详细信息\r\n\r\n　　下面我们来看另一个 quickfix 的功能。\r\n\r\n　　如果你用过 vim 的 cscope 插件，你就知道 cscope 可以用来查找相当的代码，但 cscope 需要事先生成一个数据库，对一些简单的查找，其实，我们用 vim 的 grep 命令就可以了，不需要专门为之生成数据库。vim 的 grep 命令和 shell 的几乎一样。\r\n\r\n　　我们来看个例子：\r\n\r\n　　比如我们正在浏览 nginx 的代码，这时，我想看看哪里用到了 nginx 的 NGX_HTTP_VAR_INDEXED 宏。于是，我可以在 vim 里输入如下的命令：\r\n\r\n:grep -r –include=”*.[ch]“ NGX_HTTP_VAR_INDEXED src/\r\n\r\n　　上面这个命令意思是递归查询 src 目录下所有的.c 和.h 文件，其中包括 NGX_HTTP_VAR_INDEXED 宏。然后，你就会看到 vim 到 shell 里去执行并找到了相关的文件，按回车返回 vim 后，别忘了用 【:cw 】把 grep 的输出取回来，于是我们就有下面的样子：\r\n\r\n\r\n\r\n　　然后同上面一样，你可以用 j，k 键移动 quickfix 里的光标到相应的行，然后按回车定位文件，或是使用【:cn】或【:cp】来移动到定位。（这样，你会把多个文件打开到缓冲区，别忘了【:ls】来查看缓冲区）\r\n\r\n　　你看，到这里，一个小小的 IDE 就这样产生了，而且，最帅的时，我们连一点插件都没有装，也没有在 .vimrc 文件中配置过什么。\r\n\r\n　　关键字补全\r\n\r\n　　我们还是坚持不用任何插件。我们来看看是怎么个自动补全的。\r\n\r\n　　在 insert 模式下，我们可以按如下快捷键：\r\n\r\n【Ctrl +N】  - 当你按下这它时，你会发现 Vim 就开始搜索你这个目录下的代码，搜索完成了就会出现一个下拉列表（居然是粉紫色的，真是丑死了）\r\n\r\n　　下图是我输入了 ngx_http_然后按 ctrl+n 出现的样子，它已经帮我补全了一个，但是我不想要这个。然后，在 Vim 的下方我们可以看到状态变成了“关键字补全”，然后后面有^N^P的提示，意思就是告诉你还有一个 Ctrl+P.\r\n\r\n\r\n\r\n【Ctrl + P】 – 接下来你可以按这个键，于是回到原点，然后你可以按上下光标键来选择相应的 Word。\r\n\r\n　　对于上面那个例子，我们按下了 Ctrl+P 后出现下面的这个样子。我们可以看到，光标回到了一开始我输入的位置，然后你可以干两件事，一个是继续输入（这可以帮助过滤关键词），另一个是用“光标键”上移或下移来选择下拉列表中的关键字，选好后回车，就补全了。\r\n\r\n\r\n\r\n　　与此类似的，还有更多的补齐，都在 Ctrl +X 下面：\r\n\r\nCtrl + X 和 Ctrl + D 宏定义补齐\r\nCtrl + X 和 Ctrl + ] 是 Tag 补齐\r\nCtrl + X 和 Ctrl + F 是文件名补齐\r\nCtrl + X 和 Ctrl + I 也是关键词补齐，但是关键后会有个文件名，告诉你这个关键词在哪个文件中\r\nCtrl + X 和 Ctrl +V 是表达式补齐\r\nCtrl + X 和 Ctrl +L 这可以对整个行补齐，变态吧。\r\n　　其它技巧\r\n\r\n　　字符相关\r\n\r\n　　【guu 】 – 把一行的文字变成全小写。或是【Vu】\r\n\r\n　　【gUU】 – 把一行的文件变成全大写。或是【VU】\r\n\r\n　　按【v】键进入选择模式，然后移动光标选择你要的文本，按【u】转小写，按【U】转大写\r\n\r\n　　【ga】 –  查看光标处字符的 ascii 码\r\n\r\n　　【g8】 – 查看光标处字符的 utf-8 编码\r\n\r\n　　【gf】  - 打开光标处所指的文件 （这个命令在打到#include 头文件时挺好用的，当然，仅限于有路径的）\r\n\r\n　　【*】或【#】在当前文件中搜索当前光标的单词\r\n\r\n　　缩进相关\r\n\r\n　　【>>】向右给它进当前行 【<<】向左缩进当前行\r\n\r\n　　【=】  - 缩进当前行 （和上面不一样的是，它会对齐缩进）\r\n\r\n　　【=%】 – 把光标位置移到语句块的括号上，然后按=%，缩进整个语句块（%是括号匹配）\r\n\r\n　　【G=gg】 或是 【gg=G】  - 缩进整个文件（G是到文件结尾，gg 是到文件开头）\r\n\r\n　　复制粘贴相关\r\n\r\n　　按【v】 键进入选择模式，然后按h,j,k,l移动光标，选择文本，然后按 【y】 进行复制，按 【p】 进行粘贴。\r\n\r\n　　【dd】剪切一行（前面加个数字可以剪切n行），【p】粘贴\r\n\r\n　　【yy】复制一行（前面加个数字可以复制n行），【p】粘贴\r\n\r\n　　光标移动相关\r\n\r\n　　【Ctrl + O】向后回退你的光标移动\r\n\r\n　　【Ctrl + I 】向前追赶你的光标移动\r\n\r\n　　这两个快捷键很有用，可以在 Tab 页和 Windows 中向前和向后 trace 你的光标键，这也方便你跳转光标。\r\n\r\n　　读取 Shell 命令相关\r\n\r\n　　【:r!date】 插入日期\r\n\r\n　　上面这个命令，:r 是:read 的缩写，!是表明要运行一个 shell 命令，意思是我要把 shell 命令的输出读到 vim 里来。\r\n\r\n　　vim 的终级插件\r\n\r\n　　CentOS 下：yum erase emacs\r\n\r\n　　Ubuntu 下：apt-get remove emacs\r\n\r\n　　对了，以前本站也有一篇小短文《如何在 vim 中得到你最喜爱的 IDE 特性》你也可以看看。', 5, 1, NULL, 0),
(11, '「我只是认真」——聊聊工匠情怀', '老罗的Smartisan T1手机发布会很多人应该都看了，发布会的最后老罗凝视着自己的工匠自画像，半晌没说话，随后转过身，慢慢离开舞台，屏幕下方只留下一句话：\r\n我不是为了输赢，我就是认真。\r\n　　这一瞬间让我想起93年「狮城舌战」的主角蒋昌建，在「人性本善还是人性本恶」的总结陈词最后，以顾城的名句，「黑夜给了我黑色的眼睛，我却用它寻找光明」，把整个辩论赛的氛围推向高潮。\r\n　　而老罗的这句话，和这句话背后的工匠背景，却以另外一种无声的却震人心魄的力量，敲打着每一个在场的，或是观看着整个发布会的观众的心绪。\r\n　　「工匠情怀」，我深有体会，就像我在 面向GC的Java编程 一文中所提到的：\r\n优秀程序员的价值，不在于其所掌握的几招屠龙之术，而是在细节中见真著。\r\n如果我们可以一次把事情做对，并且做好，在允许的范围内尽可能追求卓越，为什么不去做呢？\r\n　　追求卓越，追求完美，追求细节的极致。小时候看到那些修表匠，握着一个小螺丝刀，或是看着电工，用烙铁沾着锡和松香，在那一小寸的世界里，把坏了的地方修好，那种专注的眼神，觉得很厉害。\r\n　　现在再去回想那些工匠工作的场景，越发觉得钦佩。在我老家有一家刻章的店，在我上幼儿园的时候就已经在那开了很多年了。前段时间需要刻一个章，发现那家店还在，于是走进去，门口坐着一个老人，我确实记不得当年是不是他，不过看这岁数八九不离十。我以前在别的地方刻的章，都是在电脑里设计完图案后，激光刻蚀。但那次老人却是用的手刻，我着实惊呆了。只看他拿出一块红色的印底，右手持着刻刀，开始一下一下地刻着。虽然老人连话都不怎么说得清了，但是工作时那专注的神情，和精湛的手艺，以及最后成品那比机器更完美的效果，着实让我心里非常动容。\r\n　　一、技术人的执着\r\n　　我见过很多人，也见过很多程序员，都有如此的「工匠情怀」。\r\n　　做产品需求评审，有的人善于快速提供技术解决方案，在最短的时间内解决问题。\r\n　　但我见过的很多牛人，他们除了能在脑海里最快地形成方案原型，并且更深入地考虑各种细节点，最终能给出一个更趋于完善的技术方案。\r\n　　在他们身上，我看到了对这项职业的自我尊重，对自我价值的追求，也有对「卓越」的理解和渴求。\r\n　　《精通正则表达式》的译者余晟老师写过他和正则表达式的 缘起 。只是因为项目经理让他「多用Google，查查正则表达式的资料」，余老师打开了正则的大门，读完了英文原版的《Mastering Regular Expression》，如今成为了国内最了解正则表达式的人之一。\r\n　　看完那篇文章其实我想起了我的实习经历。那时候我刚去公司两三天，有一天我老板找我让我研究一下如何用Java里的MappedByteBuffer做文件内存映射来读取大文件。尽管我们当时要处理的文件很大，以我在学校编码的经验看，用普通的Reader也是可以很好地解决的。\r\n　　于是我说，「这个其实用Reader也能做，更简单一些，没那么麻烦。」\r\n　　老板反问我，「什么叫没那么麻烦，这是一个做技术的人的态度吗？」\r\n　　那几天我花了很多时间，去从Linux一直到JVM，去了解什么是内存映射，底层原理是什么，和其它技术的比较、优缺点，并和其它几种读文件的技术做了性能对比。\r\n　　虽然最后项目没有采用这个方案，但是那句反问直到现在一直在我脑海里，时时地提醒我：「做技术的人，对待技术，应该拥有什么样的态度？」\r\n　　所以其实我很感谢我的老板，以前他教我们这些新人优秀的职场习惯，有一条是每天的邮件必须没有未读数，即便是不需要阅读的邮件，也要一键置为已读，不要留一个未读的数字在那。现在想起来，有点像iOS App右上角那个提醒数的角标，有些强迫症的人怎么也忍受不了有个红圈圈在那。开个玩笑，虽然有些习惯看起来可有可无，无关紧要，但这确实映射了一种态度和思维习惯。\r\n完美有多远？我不知道，但我愿意多往前走一步。\r\n　　二、拾起初衷\r\n　　我们的生活，每天很忙碌。有时候忙得自己都忘记了为什么在此处，有时候忙得只能不断地用直觉、用以往的经验去设计一个解决方案，而没有时间去思考需求是不是合理，方案是不是最佳，我们以为自己设计的是最佳实践，谁知道呢？\r\n　　这个社会，这个世界，处在一个以不可思议的速度向前直奔的时间线上，我们处在这个时代的浪潮之上，每个人都感到了那种令人窒息的紧迫感。\r\n　　父母都是不希望孩子太累的，我们见过很多这样的话：\r\n差不多就行了。\r\n糊弄糊弄就完事了。\r\n不要与众不同。\r\n顺其自然。\r\n　　但是你应该问问自己，是不是真的要 顺其自然 ？\r\n　　我记得在上大二的时候，听一个叫端木恒的人说过一句话，大意是，这个世界上，政治可以改变很多事情，而科技，可以通过促进信息的流通，最终去推动政治的变革，去改变整个世界。\r\n　　当时觉得这事儿太酷了，是的，所以我当时的想法是，要去一个技术足够强大，并且对人们的生活有实质影响的公司。希望用技术的力量去让更多人生活地更好。\r\n　　这当然是一种不自量力，但又如何呢？只是一个普通人小小的想法，不断追求卓越，愿意比别人多往前走一步而已。\r\n　　就像冯大辉说的：\r\n所有人都说你做不成，都告诉你不要去做，不靠谱，嘲讽你，而你最后真的把事情做起来了，这就是牛逼。\r\n　　做成了，其实牛不牛逼对你自己而言已经不重要了。\r\n　　没做成，所有人都笑你是傻逼，但起码也对得起自己的内心。\r\n　　再说，如果 青年人 想的都是养老和退休，那做事的人在哪？\r\n　　三、发现更好的自己\r\n　　老罗最后的一个问题是：\r\n在一个完美主义者的眼里，这是一个怎样的世界？\r\n　　这个社会上很多人在生活上追求更高的品质，但愿意对自己手头所做的事情坚持高标准坚持卓越理念的人已经不多见了，以至于我们发现花再多的钱也买不到安全的食品了，花了一辈子的积蓄买的房子却有各种质量问题。扪心自问自己在工作中是否能坚持某些东西，大部分人的态度都差不多，只是你糊弄一下不会怎样，而他马虎一点就会死人，区别仅仅在于这里。\r\n　　M·斯科特·派克说过一句话：\r\n规避问题和逃避问题的趋向，是人类心理疾病的根源。\r\n　　很多人把随大流把妥协作为一种「成熟」的标志，小时候敢想敢说可能也敢做，长大以后懂得了人情世故，懂得向现实妥协，45度角仰望天空说自己终于长大了。再看身边那些「冥顽不灵」、「认死理」的所谓完美主义者，认为这些人才是不正常的群体，把这些人要么当做傻逼要么当做装逼。\r\n　　天哪，我都想问，「这是一个怎样的世界？」\r\n　　肯定有人会说，站着说话不腰疼。诚然，在生活中，有的人是为了活下去，有的人是为了活得更好，有的人是为了帮助别人活得更好。这是不同的人生阶段，每个人的情况不一样，但这并不影响每个人内心的精神寄托和对信念的追求。\r\n　　我从不指望去改变别人，但我相信我可以改变自己，虽然也很难。\r\n　　学生都喜欢问，如何最快地告诉自己的能力。说实话，我真的不知道什么是捷径，我的经验就是和比你优秀的人一起工作，经常请教比你资深的人，不断挑战过去的自己（每天审视自己太紧张了，只要比前段时间的自己更好就可以了）。\r\n　　四、细节是魔鬼\r\n　　Devils are in the details，细节是魔鬼，这句话很多人都听过，但要在工作中时时刻刻注意？难。\r\n　　前几天给同事做Code Review，就几行代码，发现了一个问题。\r\n　　场景是我们发现某个系统中存在占用内存超大的HTML字符串，需要统计HTML字符串的长度，于是为了获得准确的字节长度，这段代码调用的是String.getBytes().length，一眼看起来并没有什么大问题。\r\n　　但是考虑到本身这个字符串就比较大，联想到Java内部是用UTF-16存储字符串的，而getBytes()会转换为系统默认编码（GBK或是UTF-8等等），这里必然存在底层字符数组的拷贝（可以去参考String.getBytes()的源代码证实），一个本身就很大的字符串，经过拷贝，将会占用更多的内存，加剧这个问题，而在HTML中，中文其实只占了非常小的一部分，所以直接用String.length()，虽然会少数几个字符，但对统计结果影响其实并不大，并且这里不存在任何数组分配的开销。\r\n　　另外建议所有调用String.getBytes()的地方通通显式传入编码，这是个大坑。\r\n　　另外一个案例，也是在Code Review的时候发现的。\r\n　　某个调用场景下，每次都会新建一个解析器对象去解析结果，尽管解析器没有任何实例变量不会产生线程安全问题，创建的开销也并不大，但我还是坚持要改成单例，使用同一个实例去处理，这也符合面向GC编程的思想。\r\n　　这些场景，每天我们都在遇到，也许我们会说这些都是很小的问题，无伤大雅，差不多就行了。但就像前面说的，这是一种态度，一种思维习惯，当你坚持用最高的标准去要求自己，去要求自己的工作时，你才有可能渐渐接近卓越。细节是魔鬼，它会在完全察觉不到的时刻，把人拉回平庸。\r\n　　「我不是为了输赢，我就是认真。」这不代表我们不在乎输赢，从头至尾我都坚信，只有坚持完美，坚持品质，坚持那些我们曾经了解现在可能已经放弃了的美好的东西，像一个老工匠，把一种专注、追求极致的情怀融入我们的作品里，也许有一天，就有人，追寻着 梦想 ，发现了 生活更多的可能性 ，像乔布斯、像贝索斯，改变整个行业，改变全世界。\r\n　　我们是被这个时代推上浪潮之巅的人，是去做一个见证者，或是一个冲在最前面也不怕被拍死的傻瓜，是我们每个人选择的权利。\r\n　　只是不要忘记，那些傻瓜，不是真的不怕死，他们只是认真。', 6, 1, NULL, 0),
(12, 'phpcs--php代码规范检测工具', '命令： phpcs --standard=/usr/local/bin/OurATS/ main.php', 4, 1, '', 0),
(36, 'aaaa', 'aaaa', 1, 1, '', 0),
(37, 'fggg', 'gggg', 1, 1, '', 0),
(38, 'fggg6667', 'gggg666', 1, 1, '', 0),
(39, 'linux测试文章（修改）', '我是正文，但是我还是要修改一下', 1, 1, '', 0);

-- --------------------------------------------------------

--
-- Table structure for table `tag`
--

CREATE TABLE IF NOT EXISTS `tag` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(32) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=17 ;

--
-- Dumping data for table `tag`
--

INSERT INTO `tag` (`id`, `name`) VALUES
(1, 'PHP'),
(2, 'java'),
(3, 'php'),
(4, 'linux'),
(5, 'js'),
(6, 'tag1'),
(7, ' tag2'),
(8, '    tag3'),
(9, '    '),
(10, 'tag3'),
(11, 'tag2'),
(12, '666'),
(13, '6665'),
(14, '我是标签1'),
(15, '我是标签2'),
(16, '我');

-- --------------------------------------------------------

--
-- Table structure for table `tag_mid`
--

CREATE TABLE IF NOT EXISTS `tag_mid` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tag_id` int(11) NOT NULL,
  `article_id` int(11) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=23 ;

--
-- Dumping data for table `tag_mid`
--

INSERT INTO `tag_mid` (`id`, `tag_id`, `article_id`) VALUES
(1, 6, 36),
(2, 7, 36),
(3, 8, 36),
(4, 9, 36),
(5, 10, 36),
(6, 11, 36),
(7, 12, 36),
(8, 6, 37),
(9, 7, 37),
(10, 8, 37),
(11, 6, 38),
(14, 10, 38),
(15, 11, 38),
(17, 13, 38),
(18, 1, 39),
(19, 2, 39),
(21, 15, 39),
(22, 16, 39);

-- --------------------------------------------------------

--
-- Table structure for table `types`
--

CREATE TABLE IF NOT EXISTS `types` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(32) CHARACTER SET latin1 NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=7 ;

--
-- Dumping data for table `types`
--

INSERT INTO `types` (`id`, `name`) VALUES
(1, 'Linux'),
(2, 'Apache'),
(3, 'MySql'),
(4, 'PHP'),
(5, 'JavaScript'),
(6, 'Windows');

-- --------------------------------------------------------

--
-- Table structure for table `user`
--

CREATE TABLE IF NOT EXISTS `user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `email` varchar(64) NOT NULL,
  `password` varchar(64) NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `email` (`email`)
) ENGINE=InnoDB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=2 ;

--
-- Dumping data for table `user`
--

INSERT INTO `user` (`id`, `email`, `password`) VALUES
(1, 'tianyi@163.com', 'e29bddb4a06ef31e03f8d16a903b6171');

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
